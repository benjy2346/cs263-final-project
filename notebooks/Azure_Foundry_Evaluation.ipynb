{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f8bcf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-textanalytics\n",
      "  Using cached azure_ai_textanalytics-5.3.0-py3-none-any.whl.metadata (82 kB)\n",
      "Collecting azure-identity\n",
      "  Using cached azure_identity-1.25.2-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting azure-core<2.0.0,>=1.24.0 (from azure-ai-textanalytics)\n",
      "  Using cached azure_core-1.38.2-py3-none-any.whl.metadata (48 kB)\n",
      "Collecting azure-common~=1.1 (from azure-ai-textanalytics)\n",
      "  Using cached azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting isodate<1.0.0,>=0.6.1 (from azure-ai-textanalytics)\n",
      "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from azure-ai-textanalytics) (4.14.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.32.3)\n",
      "Collecting cryptography>=2.5 (from azure-identity)\n",
      "  Downloading cryptography-46.0.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting msal>=1.31.0 (from azure-identity)\n",
      "  Using cached msal-1.35.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity)\n",
      "  Using cached msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=2.5->azure-identity)\n",
      "  Downloading cffi-2.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity) (2.21)\n",
      "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal>=1.31.0->azure-identity)\n",
      "  Downloading pyjwt-2.11.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2025.8.3)\n",
      "Using cached azure_ai_textanalytics-5.3.0-py3-none-any.whl (298 kB)\n",
      "Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Using cached azure_core-1.38.2-py3-none-any.whl (217 kB)\n",
      "Using cached isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Using cached azure_identity-1.25.2-py3-none-any.whl (191 kB)\n",
      "Downloading cryptography-46.0.5-cp38-abi3-macosx_10_9_universal2.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cffi-2.0.0-cp310-cp310-macosx_11_0_arm64.whl (180 kB)\n",
      "Using cached msal-1.35.0-py3-none-any.whl (120 kB)\n",
      "Downloading pyjwt-2.11.0-py3-none-any.whl (28 kB)\n",
      "Using cached msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: azure-common, PyJWT, isodate, cffi, cryptography, azure-core, azure-ai-textanalytics, msal, msal-extensions, azure-identity\n",
      "\u001b[2K  Attempting uninstall: cffi\n",
      "\u001b[2K    Found existing installation: cffi 1.15.1\n",
      "\u001b[2K    Uninstalling cffi-1.15.1:\n",
      "\u001b[2K      Successfully uninstalled cffi-1.15.1━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [cffi]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [azure-identity]m [azure-identity]alytics]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyJWT-2.11.0 azure-ai-textanalytics-5.3.0 azure-common-1.1.28 azure-core-1.38.2 azure-identity-1.25.2 cffi-2.0.0 cryptography-46.0.5 isodate-0.7.2 msal-1.35.0 msal-extensions-1.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-ai-textanalytics azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018c1224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.11.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting spacy-stanza\n",
      "  Downloading spacy_stanza-1.0.4-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting flair\n",
      "  Downloading flair-0.15.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting emoji (from stanza)\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (2.2.6)\n",
      "Requirement already satisfied: platformdirs in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (4.3.8)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (4.25.4)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (2.32.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (3.3)\n",
      "Collecting tomli (from stanza)\n",
      "  Downloading tomli-2.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (2.4.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (4.66.5)\n",
      "Collecting udtools>=0.2.4 (from stanza)\n",
      "  Downloading udtools-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy-stanza) (3.8.11)\n",
      "Collecting stanza\n",
      "  Downloading stanza-1.6.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.24.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (63.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-stanza) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->stanza) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->stanza) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->stanza) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->stanza) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.0.0->spacy-stanza) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.1.5)\n",
      "Requirement already satisfied: typer>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.24.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from weasel<0.5.0,>=0.4.2->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from weasel<0.5.0,>=0.4.2->spacy<4.0.0,>=3.0.0->spacy-stanza) (7.5.1)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy<4.0.0,>=3.0.0->spacy-stanza) (1.16.0)\n",
      "Collecting boto3>=1.20.27 (from flair)\n",
      "  Downloading boto3-1.42.59-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting conllu<5.0.0,>=4.0 (from flair)\n",
      "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (1.2.14)\n",
      "Collecting ftfy>=6.1.0 (from flair)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting gdown>=4.4.0 (from flair)\n",
      "  Downloading gdown-5.2.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (0.24.6)\n",
      "Collecting langdetect>=1.0.9 (from flair)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (5.2.2)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (3.6.0)\n",
      "Collecting more-itertools>=8.13.0 (from flair)\n",
      "  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting mpld3>=0.3 (from flair)\n",
      "  Downloading mpld3-0.5.12-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pptree>=3.1 (from flair)\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (2.8.2)\n",
      "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
      "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (2023.10.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (1.7.2)\n",
      "Collecting segtok>=1.5.11 (from flair)\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.8.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (0.9.0)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
      "  Downloading transformer_smaller_training_vocab-0.4.2-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.25.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.44.1)\n",
      "Collecting wikipedia-api>=0.5.7 (from flair)\n",
      "  Downloading wikipedia_api-0.9.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bioc<3.0.0,>=2.0.0 (from flair)\n",
      "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading intervaltree-3.2.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting docopt (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.4.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.10.0->flair) (2023.12.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.2.0)\n",
      "Collecting botocore<1.43.0,>=1.42.59 (from boto3>=1.20.27->flair)\n",
      "  Downloading botocore-1.42.59-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
      "  Downloading jmespath-1.1.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3>=1.20.27->flair)\n",
      "  Downloading s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->flair) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ftfy>=6.1.0->flair) (0.2.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown>=4.4.0->flair) (4.11.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (23.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=2.2.3->flair) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=2.2.3->flair) (4.37.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=2.2.3->flair) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=2.2.3->flair) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn>=1.0.2->flair) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn>=1.0.2->flair) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn>=1.0.2->flair) (3.1.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (1.13.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.33.0)\n",
      "Collecting numpy (from stanza)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (5.9.2)\n",
      "Requirement already satisfied: click>=8.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (1.5.4)\n",
      "Requirement already satisfied: rich>=12.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (13.3.5)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.13.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.1.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.3.2.post1)\n",
      "Requirement already satisfied: sortedcontainers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair) (2.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.1.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch>=1.13.0->stanza) (1.3.0)\n",
      "Collecting udapi>=0.5.0 (from udtools>=0.2.4->stanza)\n",
      "  Downloading udapi-0.5.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: colorama in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from udapi>=0.5.0->udtools>=0.2.4->stanza) (0.4.6)\n",
      "Requirement already satisfied: termcolor in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from udapi>=0.5.0->udtools>=0.2.4->stanza) (2.4.0)\n",
      "Downloading spacy_stanza-1.0.4-py3-none-any.whl (9.7 kB)\n",
      "Downloading stanza-1.6.1-py3-none-any.whl (881 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.2/881.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flair-0.15.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bioc-2.1-py3-none-any.whl (33 kB)\n",
      "Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Downloading boto3-1.42.59-py3-none-any.whl (140 kB)\n",
      "Downloading botocore-1.42.59-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Downloading gdown-5.2.1-py3-none-any.whl (18 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "Downloading mpld3-0.5.12-py3-none-any.whl (203 kB)\n",
      "Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Downloading transformer_smaller_training_vocab-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading intervaltree-3.2.1-py2.py3-none-any.whl (25 kB)\n",
      "Building wheels for collected packages: langdetect, pptree, sqlitedict, wikipedia-api, docopt\n",
      "\u001b[33m  DEPRECATION: Building 'langdetect' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'langdetect'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=f5b210475492e0f330cf6e2b4be58642d23bbc556dd86c32e6c811a65806f1e7\n",
      "  Stored in directory: /Users/marvinwong/Library/Caches/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "\u001b[33m  DEPRECATION: Building 'pptree' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pptree'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for pptree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=889cf41f394972b87b76a237328aff3811f2f7d9acb300585adc246b03342b10\n",
      "  Stored in directory: /Users/marvinwong/Library/Caches/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
      "\u001b[33m  DEPRECATION: Building 'sqlitedict' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sqlitedict'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=421c2d2afde46d6f7d58d186fb826aa35b2d52257f47ee80c7353fd4e332e046\n",
      "  Stored in directory: /Users/marvinwong/Library/Caches/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
      "\u001b[33m  DEPRECATION: Building 'wikipedia-api' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'wikipedia-api'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for wikipedia-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia-api: filename=Wikipedia_API-0.9.0-py3-none-any.whl size=15423 sha256=df8e5318156a1940fe4578a9d80bf0b040af9101958a3972fbf0ca2c5057dcbf\n",
      "  Stored in directory: /Users/marvinwong/Library/Caches/pip/wheels/78/d8/ac/fe59f5cb634e5fb0b4bcd7938768e98b6b6c41edf430774197\n",
      "\u001b[33m  DEPRECATION: Building 'docopt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'docopt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=3b1593794ddcc0df9741c2b6f5d05b350dd988624d384be32f34c14889247e3a\n",
      "  Stored in directory: /Users/marvinwong/Library/Caches/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built langdetect pptree sqlitedict wikipedia-api docopt\n",
      "Installing collected packages: sqlitedict, pptree, docopt, segtok, numpy, more-itertools, langdetect, jsonlines, jmespath, intervaltree, ftfy, emoji, conllu, wikipedia-api, botocore, bioc, stanza, s3transfer, pytorch-revgrad, gdown, mpld3, boto3, transformer-smaller-training-vocab, spacy-stanza, flair\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/25\u001b[0m [flair]m24/25\u001b[0m [flair]]e]ree]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "giotto-tda 0.6.2 requires scikit-learn==1.3.2, but you have scikit-learn 1.7.2 which is incompatible.\n",
      "presidio-evaluator 0.2.5 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bioc-2.1 boto3-1.42.59 botocore-1.42.59 conllu-4.5.3 docopt-0.6.2 emoji-2.15.0 flair-0.15.1 ftfy-6.3.1 gdown-5.2.1 intervaltree-3.2.1 jmespath-1.1.0 jsonlines-4.0.0 langdetect-1.0.9 more-itertools-10.8.0 mpld3-0.5.12 numpy-1.26.4 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.16.0 segtok-1.5.11 spacy-stanza-1.0.4 sqlitedict-2.1.0 stanza-1.6.1 transformer-smaller-training-vocab-0.4.2 wikipedia-api-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stanza spacy-stanza flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40565999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdfc5bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting presidio-evaluator\n",
      "  Downloading presidio_evaluator-0.2.5-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting faker (from presidio-evaluator)\n",
      "  Downloading faker-40.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting numpy<3.0.0,>=2.0.0 (from presidio-evaluator)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-evaluator) (2.2.2)\n",
      "Collecting plotly<6.0.0,>=5.24.0 (from presidio-evaluator)\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting presidio-analyzer<3.0.0,>=2.2.351 (from presidio-evaluator)\n",
      "  Downloading presidio_analyzer-2.2.361-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting presidio-anonymizer<3.0.0,>=2.2.351 (from presidio-evaluator)\n",
      "  Downloading presidio_anonymizer-2.2.361-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-evaluator) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.25 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-evaluator) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-evaluator) (1.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.60.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-evaluator) (4.66.5)\n",
      "Collecting xmltodict<0.13.0,>=0.12.0 (from presidio-evaluator)\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.4->presidio-evaluator) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.4->presidio-evaluator) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.4->presidio-evaluator) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from plotly<6.0.0,>=5.24.0->presidio-evaluator) (8.2.2)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from plotly<6.0.0,>=5.24.0->presidio-evaluator) (24.1)\n",
      "Collecting phonenumbers<10.0.0,>=8.12 (from presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading phonenumbers-9.0.25-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pydantic<3.0.0,>=2.0.0 (from presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (6.0.1)\n",
      "Requirement already satisfied: regex in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (2023.10.3)\n",
      "Collecting spacy!=3.7.0,>=3.4.4 (from presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading spacy-3.8.11-cp310-cp310-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting tldextract (from presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading tldextract-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: cryptography>=46.0.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-anonymizer<3.0.0,>=2.2.351->presidio-evaluator) (46.0.5)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.0->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.0.0->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (4.14.1)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.0.0->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0,>=2.25->presidio-evaluator) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0,>=2.25->presidio-evaluator) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0,>=2.25->presidio-evaluator) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0,>=2.25->presidio-evaluator) (2025.8.3)\n",
      "INFO: pip is looking at multiple versions of scikit-learn to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scikit-learn<2.0.0,>=1.3.2 (from presidio-evaluator)\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.3.2->presidio-evaluator) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.3.2->presidio-evaluator) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.3.2->presidio-evaluator) (3.1.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cryptography>=46.0.4->presidio-anonymizer<3.0.0,>=2.2.351->presidio-evaluator) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cffi>=2.0.0->cryptography>=46.0.4->presidio-anonymizer<3.0.0,>=2.2.351->presidio-evaluator) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->presidio-evaluator) (1.16.0)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy>=1.8.0 (from scikit-learn<2.0.0,>=1.3.2->presidio-evaluator)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading murmurhash-1.0.15-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading cymem-2.0.13-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading preshed-3.0.12-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.5 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading thinc-8.3.10-cp310-cp310-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading srsly-2.5.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading typer_slim-0.24.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (63.2.0)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading blis-1.3.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting typer>=0.24.0 (from typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading typer-0.24.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading smart_open-7.5.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (1.16.0)\n",
      "Collecting click>=8.2.1 (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=12.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (13.3.5)\n",
      "Collecting annotated-doc>=0.0.2 (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (2.13.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (2.1.1)\n",
      "Collecting requests-file>=1.4 (from tldextract->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tldextract->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (3.13.1)\n",
      "Downloading presidio_evaluator-0.2.5-py3-none-any.whl (658 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m658.4/658.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading presidio_analyzer-2.2.361-py3-none-any.whl (183 kB)\n",
      "Downloading phonenumbers-9.0.25-py2.py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading presidio_anonymizer-2.2.361-py3-none-any.whl (36 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp310-cp310-macosx_12_0_arm64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Downloading spacy-3.8.11-cp310-cp310-macosx_11_0_arm64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.13-cp310-cp310-macosx_11_0_arm64.whl (43 kB)\n",
      "Downloading murmurhash-1.0.15-cp310-cp310-macosx_11_0_arm64.whl (27 kB)\n",
      "Downloading preshed-3.0.12-cp310-cp310-macosx_11_0_arm64.whl (124 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.2-cp310-cp310-macosx_11_0_arm64.whl (653 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.4/653.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.10-cp310-cp310-macosx_11_0_arm64.whl (772 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.3/772.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.3-cp310-cp310-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading typer_slim-0.24.0-py3-none-any.whl (3.4 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading smart_open-7.5.1-py3-none-any.whl (64 kB)\n",
      "Downloading typer-0.24.1-py3-none-any.whl (56 kB)\n",
      "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading faker-40.5.1-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tldextract-5.3.1-py3-none-any.whl (105 kB)\n",
      "Downloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
      "Installing collected packages: xmltodict, wasabi, typing-inspection, spacy-loggers, spacy-legacy, smart-open, shellingham, pydantic-core, plotly, phonenumbers, numpy, murmurhash, faker, cymem, cloudpathlib, click, catalogue, annotated-types, annotated-doc, srsly, scipy, requests-file, pydantic, preshed, blis, typer, tldextract, scikit-learn, presidio-anonymizer, confection, typer-slim, thinc, weasel, spacy, presidio-analyzer, presidio-evaluator\n",
      "\u001b[2K  Attempting uninstall: plotly\n",
      "\u001b[2K    Found existing installation: plotly 5.14.1\n",
      "\u001b[2K    Uninstalling plotly-5.14.1:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/36\u001b[0m [plotly]\n",
      "\u001b[2K      Successfully uninstalled plotly-5.14.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/36\u001b[0m [plotly]\n",
      "\u001b[2K  Attempting uninstall: numpy[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/36\u001b[0m [phonenumbers]\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/36\u001b[0m [phonenumbers]\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/36\u001b[0m [phonenumbers]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/36\u001b[0m [phonenumbers]\n",
      "\u001b[2K  Attempting uninstall: clickm╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/36\u001b[0m [faker]rs]\n",
      "\u001b[2K    Found existing installation: click 8.1.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/36\u001b[0m [faker]\n",
      "\u001b[2K    Uninstalling click-8.1.3:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/36\u001b[0m [faker]\n",
      "\u001b[2K      Successfully uninstalled click-8.1.3━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/36\u001b[0m [faker]\n",
      "\u001b[2K  Attempting uninstall: scipy[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/36\u001b[0m [click]\n",
      "\u001b[2K    Found existing installation: scipy 1.10.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/36\u001b[0m [click]\n",
      "\u001b[2K    Uninstalling scipy-1.10.0:\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/36\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.10.00m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/36\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: scikit-learn\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [pydantic]\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.3.2━━━━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling scikit-learn-1.3.2:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [pydantic]\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.3.2━━━━━━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [pydantic]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/36\u001b[0m [presidio-evaluator]pacy]slim]n]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "accelerate 0.33.0 requires numpy<2.0.0,>=1.17, but you have numpy 2.2.6 which is incompatible.\n",
      "derivative 0.6.2 requires numpy<2.0.0,>=1.18.3, but you have numpy 2.2.6 which is incompatible.\n",
      "giotto-tda 0.6.2 requires scikit-learn==1.3.2, but you have scikit-learn 1.7.2 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-doc-0.0.4 annotated-types-0.7.0 blis-1.3.3 catalogue-2.0.10 click-8.3.1 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 faker-40.5.1 murmurhash-1.0.15 numpy-2.2.6 phonenumbers-9.0.25 plotly-5.24.1 preshed-3.0.12 presidio-analyzer-2.2.361 presidio-anonymizer-2.2.361 presidio-evaluator-0.2.5 pydantic-2.12.5 pydantic-core-2.41.5 requests-file-3.0.1 scikit-learn-1.7.2 scipy-1.15.3 shellingham-1.5.4 smart-open-7.5.1 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 thinc-8.3.10 tldextract-5.3.1 typer-0.24.1 typer-slim-0.24.0 typing-inspection-0.4.2 wasabi-1.1.3 weasel-0.4.3 xmltodict-0.12.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install presidio-evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "851157d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "endpoint = os.environ.get(\"AZURE_LANGUAGE_ENDPOINT\")\n",
    "key = os.environ.get(\"AZURE_LANGUAGE_KEY\")\n",
    "\n",
    "if not key or not endpoint:\n",
    "    raise ValueError(\"Missing Azure keys! Check your .env file.\")\n",
    "\n",
    "# 4. Connect to Azure\n",
    "client = TextAnalyticsClient(endpoint, AzureKeyCredential(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1835cf4f",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd3eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_PII_MAPPING = {\n",
    "    'ADDRESS': 'Address',\n",
    "    'AGE': 'Age',\n",
    "    'BIRTHDAY': 'DateTime',\n",
    "    'CITY': 'Location',               # Azure often categorizes cities as Location or Address\n",
    "    'CREDIT_CARD': 'CreditCardNumber',\n",
    "    'CREDIT_CARD_NUMBER': 'CreditCardNumber',\n",
    "    'DATE': 'DateTime',\n",
    "    'DATE_OF_BIRTH': 'DateTime',\n",
    "    'DATE_TIME': 'DateTime',\n",
    "    'DOB': 'DateTime',\n",
    "    'DOMAIN': 'URL',\n",
    "    'DOMAIN_NAME': 'URL',\n",
    "    'EMAIL': 'Email',\n",
    "    'EMAIL_ADDRESS': 'Email',\n",
    "    'FACILITY': 'Organization',       # Facilities/Hospitals roll into Organization\n",
    "    'FIRST_NAME': 'Person',\n",
    "    'GPE': 'Location',\n",
    "    'HCW': 'Person',                  # Health Care Worker\n",
    "    'HOSP': 'Organization',\n",
    "    'HOSPITAL': 'Organization',\n",
    "    'IBAN': 'InternationalBankingAccountNumber',\n",
    "    'IBAN_CODE': 'InternationalBankingAccountNumber',\n",
    "    'ID': 'NationalIdentityNumber',   # Generic fallback for IDs in Azure\n",
    "    'IP_ADDRESS': 'IPAddress',\n",
    "    'LAST_NAME': 'Person',\n",
    "    'LOC': 'Location',\n",
    "    'LOCATION': 'Location',\n",
    "    'NAME': 'Person',\n",
    "    'NATIONALITY': 'O',               # Azure PII doesn't strictly flag Nationality/NRP as PII\n",
    "    'NORP': 'O',                      # (Nationalities, Religious, Political groups)\n",
    "    'NRP': 'O',\n",
    "    'O': 'O',\n",
    "    'ORG': 'Organization',\n",
    "    'ORGANIZATION': 'Organization',\n",
    "    'PATIENT': 'Person',\n",
    "    'PATORG': 'Organization',\n",
    "    'PER': 'Person',\n",
    "    'PERSON': 'Person',\n",
    "    'PHONE': 'PhoneNumber',\n",
    "    'PHONE_NUMBER': 'PhoneNumber',\n",
    "    'PREFIX': 'PersonType',           # Azure uses PersonType for Mr., Mrs., Dr., etc.\n",
    "    'SSN': 'USSocialSecurityNumber',\n",
    "    'STAFF': 'Person',\n",
    "    'STREET_ADDRESS': 'Address',\n",
    "    'TIME': 'DateTime',\n",
    "    'TITLE': 'PersonType',            # Azure uses PersonType for job titles/roles\n",
    "    'URL': 'URL',\n",
    "    'US_DRIVER_LICENSE': 'USDriversLicenseNumber',\n",
    "    'US_SSN': 'USSocialSecurityNumber',\n",
    "    'VENDOR': 'Organization',\n",
    "    'ZIP': 'Address',                 # Azure groups zip codes under the larger Address entity\n",
    "    'ZIP_CODE': 'Address'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ca9db",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d131836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "    \"\"\"Loads the JSON dataset from the specified file path.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "046dcf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the data from your specific JSON file\n",
    "json_file_path = \"../data/synth_dataset_v2.original.json\"\n",
    "my_dataset = load_dataset(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3fbbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "obfuscated_file_path = \"../data/synth_dataset_v2.json\"\n",
    "obfuscated_dataset = load_dataset(obfuscated_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3983efd8",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bff77bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation_presidio_replica(dataset):\n",
    "    all_ground_truth_sets = []\n",
    "    all_predicted_sets = []\n",
    "    \n",
    "    batch_size = 5\n",
    "    total_docs = len(dataset)\n",
    "    print(f\"Processing {total_docs} documents for Azure Evaluation...\\n\")\n",
    "    \n",
    "    # --- 1 & 2. FETCH AND FORMAT DATA ---\n",
    "    for i in range(0, total_docs, batch_size):\n",
    "        batch = dataset[i:i + batch_size]\n",
    "        texts = [doc[\"full_text\"] for doc in batch]\n",
    "        \n",
    "        # Call Azure API\n",
    "        response = client.recognize_pii_entities(texts, language=\"en\")\n",
    "        \n",
    "        for doc_idx, result in enumerate(response):\n",
    "            if result.is_error:\n",
    "                all_ground_truth_sets.append(set())\n",
    "                all_predicted_sets.append(set())\n",
    "                continue\n",
    "            \n",
    "            # Ground Truth Tuples: (Type, Start, End)\n",
    "            doc_gt = set()\n",
    "            for span in batch[doc_idx][\"spans\"]:\n",
    "                mapped_type = AZURE_PII_MAPPING.get(span[\"entity_type\"], span[\"entity_type\"])\n",
    "                if mapped_type != 'O': \n",
    "                    doc_gt.add((mapped_type, span[\"start_position\"], span[\"end_position\"]))\n",
    "            all_ground_truth_sets.append(doc_gt)\n",
    "            \n",
    "            # Predicted Tuples: (Type, Start, End)\n",
    "            doc_pred = set()\n",
    "            for entity in result.entities:\n",
    "                doc_pred.add((entity.category, entity.offset, entity.offset + entity.length))\n",
    "            all_predicted_sets.append(doc_pred)\n",
    "            \n",
    "        print(f\"Processed {min(i + batch_size, total_docs)} / {total_docs} documents...\")\n",
    "\n",
    "    # --- 3. CALCULATE STRICT & SOFT METRICS (Presidio Replica) ---\n",
    "    print(\"\\nCalculating metrics using Presidio 1:1 Greedy Matching...\")\n",
    "    \n",
    "    total_gt = 0\n",
    "    total_pred = 0\n",
    "    \n",
    "    strict_matched = 0\n",
    "    soft_matched = 0\n",
    "    \n",
    "    for gt_set, pred_set in zip(all_ground_truth_sets, all_predicted_sets):\n",
    "        total_gt += len(gt_set)\n",
    "        total_pred += len(pred_set)\n",
    "        \n",
    "        # STRICT MATCHES: Exact set intersection\n",
    "        strict_matched += len(gt_set.intersection(pred_set))\n",
    "        \n",
    "        # SOFT MATCHES: Greedy 1:1 Bipartite Matching\n",
    "        gt_list = list(gt_set)\n",
    "        pred_list = list(pred_set)\n",
    "        overlaps = []\n",
    "        \n",
    "        # Step A: Find all overlapping pairs and calculate the size of the overlap\n",
    "        for gt_idx, gt in enumerate(gt_list):\n",
    "            gt_type, gt_start, gt_end = gt\n",
    "            for pred_idx, pred in enumerate(pred_list):\n",
    "                pred_type, pred_start, pred_end = pred\n",
    "                \n",
    "                if gt_type == pred_type:\n",
    "                    overlap_length = min(gt_end, pred_end) - max(gt_start, pred_start)\n",
    "                    if overlap_length > 0:\n",
    "                        overlaps.append((overlap_length, gt_idx, pred_idx))\n",
    "                        \n",
    "        # Step B: Sort by largest overlap first\n",
    "        overlaps.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # Step C: Assign matches greedily (1-to-1)\n",
    "        claimed_gts = set()\n",
    "        claimed_preds = set()\n",
    "        \n",
    "        for overlap_length, gt_idx, pred_idx in overlaps:\n",
    "            if gt_idx not in claimed_gts and pred_idx not in claimed_preds:\n",
    "                claimed_gts.add(gt_idx)\n",
    "                claimed_preds.add(pred_idx)\n",
    "                soft_matched += 1\n",
    "\n",
    "    # --- 4. FINALIZE MATH ---\n",
    "    def calc_f1(precision, recall):\n",
    "        return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    # Strict Math\n",
    "    strict_precision = strict_matched / total_pred if total_pred > 0 else 0.0\n",
    "    strict_recall = strict_matched / total_gt if total_gt > 0 else 0.0\n",
    "    strict_f1 = calc_f1(strict_precision, strict_recall)\n",
    "\n",
    "    # Soft Math\n",
    "    soft_precision = soft_matched / total_pred if total_pred > 0 else 0.0\n",
    "    soft_recall = soft_matched / total_gt if total_gt > 0 else 0.0\n",
    "    soft_f1 = calc_f1(soft_precision, soft_recall)\n",
    "\n",
    "    # --- 5. PRINT RESULTS ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"      AZURE PII EVALUATION RESULTS      \")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total Ground Truth Entities: {total_gt}\")\n",
    "    print(f\"Total Predicted Entities:    {total_pred}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\" STRICT MATCHING (Exact Character Bounds)\")\n",
    "    print(f\"   Precision: {strict_precision:.4f}\")\n",
    "    print(f\"   Recall:    {strict_recall:.4f}\")\n",
    "    print(f\"   F1-Score:  {strict_f1:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\" SOFT MATCHING (1:1 Greedy Overlap)\")\n",
    "    print(f\"   Precision: {soft_precision:.4f}\")\n",
    "    print(f\"   Recall:    {soft_recall:.4f}\")\n",
    "    print(f\"   F1-Score:  {soft_f1:.4f}\")\n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1956ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_evaluation_presidio_replica(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b48bf8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6000 documents for Azure Evaluation...\n",
      "\n",
      "Processed 5 / 6000 documents...\n",
      "Processed 10 / 6000 documents...\n",
      "Processed 15 / 6000 documents...\n",
      "Processed 20 / 6000 documents...\n",
      "Processed 25 / 6000 documents...\n",
      "Processed 30 / 6000 documents...\n",
      "Processed 35 / 6000 documents...\n",
      "Processed 40 / 6000 documents...\n",
      "Processed 45 / 6000 documents...\n",
      "Processed 50 / 6000 documents...\n",
      "Processed 55 / 6000 documents...\n",
      "Processed 60 / 6000 documents...\n",
      "Processed 65 / 6000 documents...\n",
      "Processed 70 / 6000 documents...\n",
      "Processed 75 / 6000 documents...\n",
      "Processed 80 / 6000 documents...\n",
      "Processed 85 / 6000 documents...\n",
      "Processed 90 / 6000 documents...\n",
      "Processed 95 / 6000 documents...\n",
      "Processed 100 / 6000 documents...\n",
      "Processed 105 / 6000 documents...\n",
      "Processed 110 / 6000 documents...\n",
      "Processed 115 / 6000 documents...\n",
      "Processed 120 / 6000 documents...\n",
      "Processed 125 / 6000 documents...\n",
      "Processed 130 / 6000 documents...\n",
      "Processed 135 / 6000 documents...\n",
      "Processed 140 / 6000 documents...\n",
      "Processed 145 / 6000 documents...\n",
      "Processed 150 / 6000 documents...\n",
      "Processed 155 / 6000 documents...\n",
      "Processed 160 / 6000 documents...\n",
      "Processed 165 / 6000 documents...\n",
      "Processed 170 / 6000 documents...\n",
      "Processed 175 / 6000 documents...\n",
      "Processed 180 / 6000 documents...\n",
      "Processed 185 / 6000 documents...\n",
      "Processed 190 / 6000 documents...\n",
      "Processed 195 / 6000 documents...\n",
      "Processed 200 / 6000 documents...\n",
      "Processed 205 / 6000 documents...\n",
      "Processed 210 / 6000 documents...\n",
      "Processed 215 / 6000 documents...\n",
      "Processed 220 / 6000 documents...\n",
      "Processed 225 / 6000 documents...\n",
      "Processed 230 / 6000 documents...\n",
      "Processed 235 / 6000 documents...\n",
      "Processed 240 / 6000 documents...\n",
      "Processed 245 / 6000 documents...\n",
      "Processed 250 / 6000 documents...\n",
      "Processed 255 / 6000 documents...\n",
      "Processed 260 / 6000 documents...\n",
      "Processed 265 / 6000 documents...\n",
      "Processed 270 / 6000 documents...\n",
      "Processed 275 / 6000 documents...\n",
      "Processed 280 / 6000 documents...\n",
      "Processed 285 / 6000 documents...\n",
      "Processed 290 / 6000 documents...\n",
      "Processed 295 / 6000 documents...\n",
      "Processed 300 / 6000 documents...\n",
      "Processed 305 / 6000 documents...\n",
      "Processed 310 / 6000 documents...\n",
      "Processed 315 / 6000 documents...\n",
      "Processed 320 / 6000 documents...\n",
      "Processed 325 / 6000 documents...\n",
      "Processed 330 / 6000 documents...\n",
      "Processed 335 / 6000 documents...\n",
      "Processed 340 / 6000 documents...\n",
      "Processed 345 / 6000 documents...\n",
      "Processed 350 / 6000 documents...\n",
      "Processed 355 / 6000 documents...\n",
      "Processed 360 / 6000 documents...\n",
      "Processed 365 / 6000 documents...\n",
      "Processed 370 / 6000 documents...\n",
      "Processed 375 / 6000 documents...\n",
      "Processed 380 / 6000 documents...\n",
      "Processed 385 / 6000 documents...\n",
      "Processed 390 / 6000 documents...\n",
      "Processed 395 / 6000 documents...\n",
      "Processed 400 / 6000 documents...\n",
      "Processed 405 / 6000 documents...\n",
      "Processed 410 / 6000 documents...\n",
      "Processed 415 / 6000 documents...\n",
      "Processed 420 / 6000 documents...\n",
      "Processed 425 / 6000 documents...\n",
      "Processed 430 / 6000 documents...\n",
      "Processed 435 / 6000 documents...\n",
      "Processed 440 / 6000 documents...\n",
      "Processed 445 / 6000 documents...\n",
      "Processed 450 / 6000 documents...\n",
      "Processed 455 / 6000 documents...\n",
      "Processed 460 / 6000 documents...\n",
      "Processed 465 / 6000 documents...\n",
      "Processed 470 / 6000 documents...\n",
      "Processed 475 / 6000 documents...\n",
      "Processed 480 / 6000 documents...\n",
      "Processed 485 / 6000 documents...\n",
      "Processed 490 / 6000 documents...\n",
      "Processed 495 / 6000 documents...\n",
      "Processed 500 / 6000 documents...\n",
      "Processed 505 / 6000 documents...\n",
      "Processed 510 / 6000 documents...\n",
      "Processed 515 / 6000 documents...\n",
      "Processed 520 / 6000 documents...\n",
      "Processed 525 / 6000 documents...\n",
      "Processed 530 / 6000 documents...\n",
      "Processed 535 / 6000 documents...\n",
      "Processed 540 / 6000 documents...\n",
      "Processed 545 / 6000 documents...\n",
      "Processed 550 / 6000 documents...\n",
      "Processed 555 / 6000 documents...\n",
      "Processed 560 / 6000 documents...\n",
      "Processed 565 / 6000 documents...\n",
      "Processed 570 / 6000 documents...\n",
      "Processed 575 / 6000 documents...\n",
      "Processed 580 / 6000 documents...\n",
      "Processed 585 / 6000 documents...\n",
      "Processed 590 / 6000 documents...\n",
      "Processed 595 / 6000 documents...\n",
      "Processed 600 / 6000 documents...\n",
      "Processed 605 / 6000 documents...\n",
      "Processed 610 / 6000 documents...\n",
      "Processed 615 / 6000 documents...\n",
      "Processed 620 / 6000 documents...\n",
      "Processed 625 / 6000 documents...\n",
      "Processed 630 / 6000 documents...\n",
      "Processed 635 / 6000 documents...\n",
      "Processed 640 / 6000 documents...\n",
      "Processed 645 / 6000 documents...\n",
      "Processed 650 / 6000 documents...\n",
      "Processed 655 / 6000 documents...\n",
      "Processed 660 / 6000 documents...\n",
      "Processed 665 / 6000 documents...\n",
      "Processed 670 / 6000 documents...\n",
      "Processed 675 / 6000 documents...\n",
      "Processed 680 / 6000 documents...\n",
      "Processed 685 / 6000 documents...\n",
      "Processed 690 / 6000 documents...\n",
      "Processed 695 / 6000 documents...\n",
      "Processed 700 / 6000 documents...\n",
      "Processed 705 / 6000 documents...\n",
      "Processed 710 / 6000 documents...\n",
      "Processed 715 / 6000 documents...\n",
      "Processed 720 / 6000 documents...\n",
      "Processed 725 / 6000 documents...\n",
      "Processed 730 / 6000 documents...\n",
      "Processed 735 / 6000 documents...\n",
      "Processed 740 / 6000 documents...\n",
      "Processed 745 / 6000 documents...\n",
      "Processed 750 / 6000 documents...\n",
      "Processed 755 / 6000 documents...\n",
      "Processed 760 / 6000 documents...\n",
      "Processed 765 / 6000 documents...\n",
      "Processed 770 / 6000 documents...\n",
      "Processed 775 / 6000 documents...\n",
      "Processed 780 / 6000 documents...\n",
      "Processed 785 / 6000 documents...\n",
      "Processed 790 / 6000 documents...\n",
      "Processed 795 / 6000 documents...\n",
      "Processed 800 / 6000 documents...\n",
      "Processed 805 / 6000 documents...\n",
      "Processed 810 / 6000 documents...\n",
      "Processed 815 / 6000 documents...\n",
      "Processed 820 / 6000 documents...\n",
      "Processed 825 / 6000 documents...\n",
      "Processed 830 / 6000 documents...\n",
      "Processed 835 / 6000 documents...\n",
      "Processed 840 / 6000 documents...\n",
      "Processed 845 / 6000 documents...\n",
      "Processed 850 / 6000 documents...\n",
      "Processed 855 / 6000 documents...\n",
      "Processed 860 / 6000 documents...\n",
      "Processed 865 / 6000 documents...\n",
      "Processed 870 / 6000 documents...\n",
      "Processed 875 / 6000 documents...\n",
      "Processed 880 / 6000 documents...\n",
      "Processed 885 / 6000 documents...\n",
      "Processed 890 / 6000 documents...\n",
      "Processed 895 / 6000 documents...\n",
      "Processed 900 / 6000 documents...\n",
      "Processed 905 / 6000 documents...\n",
      "Processed 910 / 6000 documents...\n",
      "Processed 915 / 6000 documents...\n",
      "Processed 920 / 6000 documents...\n",
      "Processed 925 / 6000 documents...\n",
      "Processed 930 / 6000 documents...\n",
      "Processed 935 / 6000 documents...\n",
      "Processed 940 / 6000 documents...\n",
      "Processed 945 / 6000 documents...\n",
      "Processed 950 / 6000 documents...\n",
      "Processed 955 / 6000 documents...\n",
      "Processed 960 / 6000 documents...\n",
      "Processed 965 / 6000 documents...\n",
      "Processed 970 / 6000 documents...\n",
      "Processed 975 / 6000 documents...\n",
      "Processed 980 / 6000 documents...\n",
      "Processed 985 / 6000 documents...\n",
      "Processed 990 / 6000 documents...\n",
      "Processed 995 / 6000 documents...\n",
      "Processed 1000 / 6000 documents...\n",
      "Processed 1005 / 6000 documents...\n",
      "Processed 1010 / 6000 documents...\n",
      "Processed 1015 / 6000 documents...\n",
      "Processed 1020 / 6000 documents...\n",
      "Processed 1025 / 6000 documents...\n",
      "Processed 1030 / 6000 documents...\n",
      "Processed 1035 / 6000 documents...\n",
      "Processed 1040 / 6000 documents...\n",
      "Processed 1045 / 6000 documents...\n",
      "Processed 1050 / 6000 documents...\n",
      "Processed 1055 / 6000 documents...\n",
      "Processed 1060 / 6000 documents...\n",
      "Processed 1065 / 6000 documents...\n",
      "Processed 1070 / 6000 documents...\n",
      "Processed 1075 / 6000 documents...\n",
      "Processed 1080 / 6000 documents...\n",
      "Processed 1085 / 6000 documents...\n",
      "Processed 1090 / 6000 documents...\n",
      "Processed 1095 / 6000 documents...\n",
      "Processed 1100 / 6000 documents...\n",
      "Processed 1105 / 6000 documents...\n",
      "Processed 1110 / 6000 documents...\n",
      "Processed 1115 / 6000 documents...\n",
      "Processed 1120 / 6000 documents...\n",
      "Processed 1125 / 6000 documents...\n",
      "Processed 1130 / 6000 documents...\n",
      "Processed 1135 / 6000 documents...\n",
      "Processed 1140 / 6000 documents...\n",
      "Processed 1145 / 6000 documents...\n",
      "Processed 1150 / 6000 documents...\n",
      "Processed 1155 / 6000 documents...\n",
      "Processed 1160 / 6000 documents...\n",
      "Processed 1165 / 6000 documents...\n",
      "Processed 1170 / 6000 documents...\n",
      "Processed 1175 / 6000 documents...\n",
      "Processed 1180 / 6000 documents...\n",
      "Processed 1185 / 6000 documents...\n",
      "Processed 1190 / 6000 documents...\n",
      "Processed 1195 / 6000 documents...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1200 / 6000 documents...\n",
      "Processed 1205 / 6000 documents...\n",
      "Processed 1210 / 6000 documents...\n",
      "Processed 1215 / 6000 documents...\n",
      "Processed 1220 / 6000 documents...\n",
      "Processed 1225 / 6000 documents...\n",
      "Processed 1230 / 6000 documents...\n",
      "Processed 1235 / 6000 documents...\n",
      "Processed 1240 / 6000 documents...\n",
      "Processed 1245 / 6000 documents...\n",
      "Processed 1250 / 6000 documents...\n",
      "Processed 1255 / 6000 documents...\n",
      "Processed 1260 / 6000 documents...\n",
      "Processed 1265 / 6000 documents...\n",
      "Processed 1270 / 6000 documents...\n",
      "Processed 1275 / 6000 documents...\n",
      "Processed 1280 / 6000 documents...\n",
      "Processed 1285 / 6000 documents...\n",
      "Processed 1290 / 6000 documents...\n",
      "Processed 1295 / 6000 documents...\n",
      "Processed 1300 / 6000 documents...\n",
      "Processed 1305 / 6000 documents...\n",
      "Processed 1310 / 6000 documents...\n",
      "Processed 1315 / 6000 documents...\n",
      "Processed 1320 / 6000 documents...\n",
      "Processed 1325 / 6000 documents...\n",
      "Processed 1330 / 6000 documents...\n",
      "Processed 1335 / 6000 documents...\n",
      "Processed 1340 / 6000 documents...\n",
      "Processed 1345 / 6000 documents...\n",
      "Processed 1350 / 6000 documents...\n",
      "Processed 1355 / 6000 documents...\n",
      "Processed 1360 / 6000 documents...\n",
      "Processed 1365 / 6000 documents...\n",
      "Processed 1370 / 6000 documents...\n",
      "Processed 1375 / 6000 documents...\n",
      "Processed 1380 / 6000 documents...\n",
      "Processed 1385 / 6000 documents...\n",
      "Processed 1390 / 6000 documents...\n",
      "Processed 1395 / 6000 documents...\n",
      "Processed 1400 / 6000 documents...\n",
      "Processed 1405 / 6000 documents...\n",
      "Processed 1410 / 6000 documents...\n",
      "Processed 1415 / 6000 documents...\n",
      "Processed 1420 / 6000 documents...\n",
      "Processed 1425 / 6000 documents...\n",
      "Processed 1430 / 6000 documents...\n",
      "Processed 1435 / 6000 documents...\n",
      "Processed 1440 / 6000 documents...\n",
      "Processed 1445 / 6000 documents...\n",
      "Processed 1450 / 6000 documents...\n",
      "Processed 1455 / 6000 documents...\n",
      "Processed 1460 / 6000 documents...\n",
      "Processed 1465 / 6000 documents...\n",
      "Processed 1470 / 6000 documents...\n",
      "Processed 1475 / 6000 documents...\n",
      "Processed 1480 / 6000 documents...\n",
      "Processed 1485 / 6000 documents...\n",
      "Processed 1490 / 6000 documents...\n",
      "Processed 1495 / 6000 documents...\n",
      "Processed 1500 / 6000 documents...\n",
      "Processed 1505 / 6000 documents...\n",
      "Processed 1510 / 6000 documents...\n",
      "Processed 1515 / 6000 documents...\n",
      "Processed 1520 / 6000 documents...\n",
      "Processed 1525 / 6000 documents...\n",
      "Processed 1530 / 6000 documents...\n",
      "Processed 1535 / 6000 documents...\n",
      "Processed 1540 / 6000 documents...\n",
      "Processed 1545 / 6000 documents...\n",
      "Processed 1550 / 6000 documents...\n",
      "Processed 1555 / 6000 documents...\n",
      "Processed 1560 / 6000 documents...\n",
      "Processed 1565 / 6000 documents...\n",
      "Processed 1570 / 6000 documents...\n",
      "Processed 1575 / 6000 documents...\n",
      "Processed 1580 / 6000 documents...\n",
      "Processed 1585 / 6000 documents...\n",
      "Processed 1590 / 6000 documents...\n",
      "Processed 1595 / 6000 documents...\n",
      "Processed 1600 / 6000 documents...\n",
      "Processed 1605 / 6000 documents...\n",
      "Processed 1610 / 6000 documents...\n",
      "Processed 1615 / 6000 documents...\n",
      "Processed 1620 / 6000 documents...\n",
      "Processed 1625 / 6000 documents...\n",
      "Processed 1630 / 6000 documents...\n",
      "Processed 1635 / 6000 documents...\n",
      "Processed 1640 / 6000 documents...\n",
      "Processed 1645 / 6000 documents...\n",
      "Processed 1650 / 6000 documents...\n",
      "Processed 1655 / 6000 documents...\n",
      "Processed 1660 / 6000 documents...\n",
      "Processed 1665 / 6000 documents...\n",
      "Processed 1670 / 6000 documents...\n",
      "Processed 1675 / 6000 documents...\n",
      "Processed 1680 / 6000 documents...\n",
      "Processed 1685 / 6000 documents...\n",
      "Processed 1690 / 6000 documents...\n",
      "Processed 1695 / 6000 documents...\n",
      "Processed 1700 / 6000 documents...\n",
      "Processed 1705 / 6000 documents...\n",
      "Processed 1710 / 6000 documents...\n",
      "Processed 1715 / 6000 documents...\n",
      "Processed 1720 / 6000 documents...\n",
      "Processed 1725 / 6000 documents...\n",
      "Processed 1730 / 6000 documents...\n",
      "Processed 1735 / 6000 documents...\n",
      "Processed 1740 / 6000 documents...\n",
      "Processed 1745 / 6000 documents...\n",
      "Processed 1750 / 6000 documents...\n",
      "Processed 1755 / 6000 documents...\n",
      "Processed 1760 / 6000 documents...\n",
      "Processed 1765 / 6000 documents...\n",
      "Processed 1770 / 6000 documents...\n",
      "Processed 1775 / 6000 documents...\n",
      "Processed 1780 / 6000 documents...\n",
      "Processed 1785 / 6000 documents...\n",
      "Processed 1790 / 6000 documents...\n",
      "Processed 1795 / 6000 documents...\n",
      "Processed 1800 / 6000 documents...\n",
      "Processed 1805 / 6000 documents...\n",
      "Processed 1810 / 6000 documents...\n",
      "Processed 1815 / 6000 documents...\n",
      "Processed 1820 / 6000 documents...\n",
      "Processed 1825 / 6000 documents...\n",
      "Processed 1830 / 6000 documents...\n",
      "Processed 1835 / 6000 documents...\n",
      "Processed 1840 / 6000 documents...\n",
      "Processed 1845 / 6000 documents...\n",
      "Processed 1850 / 6000 documents...\n",
      "Processed 1855 / 6000 documents...\n",
      "Processed 1860 / 6000 documents...\n",
      "Processed 1865 / 6000 documents...\n",
      "Processed 1870 / 6000 documents...\n",
      "Processed 1875 / 6000 documents...\n",
      "Processed 1880 / 6000 documents...\n",
      "Processed 1885 / 6000 documents...\n",
      "Processed 1890 / 6000 documents...\n",
      "Processed 1895 / 6000 documents...\n",
      "Processed 1900 / 6000 documents...\n",
      "Processed 1905 / 6000 documents...\n",
      "Processed 1910 / 6000 documents...\n",
      "Processed 1915 / 6000 documents...\n",
      "Processed 1920 / 6000 documents...\n",
      "Processed 1925 / 6000 documents...\n",
      "Processed 1930 / 6000 documents...\n",
      "Processed 1935 / 6000 documents...\n",
      "Processed 1940 / 6000 documents...\n",
      "Processed 1945 / 6000 documents...\n",
      "Processed 1950 / 6000 documents...\n",
      "Processed 1955 / 6000 documents...\n",
      "Processed 1960 / 6000 documents...\n",
      "Processed 1965 / 6000 documents...\n",
      "Processed 1970 / 6000 documents...\n",
      "Processed 1975 / 6000 documents...\n",
      "Processed 1980 / 6000 documents...\n",
      "Processed 1985 / 6000 documents...\n",
      "Processed 1990 / 6000 documents...\n",
      "Processed 1995 / 6000 documents...\n",
      "Processed 2000 / 6000 documents...\n",
      "Processed 2005 / 6000 documents...\n",
      "Processed 2010 / 6000 documents...\n",
      "Processed 2015 / 6000 documents...\n",
      "Processed 2020 / 6000 documents...\n",
      "Processed 2025 / 6000 documents...\n",
      "Processed 2030 / 6000 documents...\n",
      "Processed 2035 / 6000 documents...\n",
      "Processed 2040 / 6000 documents...\n",
      "Processed 2045 / 6000 documents...\n",
      "Processed 2050 / 6000 documents...\n",
      "Processed 2055 / 6000 documents...\n",
      "Processed 2060 / 6000 documents...\n",
      "Processed 2065 / 6000 documents...\n",
      "Processed 2070 / 6000 documents...\n",
      "Processed 2075 / 6000 documents...\n",
      "Processed 2080 / 6000 documents...\n",
      "Processed 2085 / 6000 documents...\n",
      "Processed 2090 / 6000 documents...\n",
      "Processed 2095 / 6000 documents...\n",
      "Processed 2100 / 6000 documents...\n",
      "Processed 2105 / 6000 documents...\n",
      "Processed 2110 / 6000 documents...\n",
      "Processed 2115 / 6000 documents...\n",
      "Processed 2120 / 6000 documents...\n",
      "Processed 2125 / 6000 documents...\n",
      "Processed 2130 / 6000 documents...\n",
      "Processed 2135 / 6000 documents...\n",
      "Processed 2140 / 6000 documents...\n",
      "Processed 2145 / 6000 documents...\n",
      "Processed 2150 / 6000 documents...\n",
      "Processed 2155 / 6000 documents...\n",
      "Processed 2160 / 6000 documents...\n",
      "Processed 2165 / 6000 documents...\n",
      "Processed 2170 / 6000 documents...\n",
      "Processed 2175 / 6000 documents...\n",
      "Processed 2180 / 6000 documents...\n",
      "Processed 2185 / 6000 documents...\n",
      "Processed 2190 / 6000 documents...\n",
      "Processed 2195 / 6000 documents...\n",
      "Processed 2200 / 6000 documents...\n",
      "Processed 2205 / 6000 documents...\n",
      "Processed 2210 / 6000 documents...\n",
      "Processed 2215 / 6000 documents...\n",
      "Processed 2220 / 6000 documents...\n",
      "Processed 2225 / 6000 documents...\n",
      "Processed 2230 / 6000 documents...\n",
      "Processed 2235 / 6000 documents...\n",
      "Processed 2240 / 6000 documents...\n",
      "Processed 2245 / 6000 documents...\n",
      "Processed 2250 / 6000 documents...\n",
      "Processed 2255 / 6000 documents...\n",
      "Processed 2260 / 6000 documents...\n",
      "Processed 2265 / 6000 documents...\n",
      "Processed 2270 / 6000 documents...\n",
      "Processed 2275 / 6000 documents...\n",
      "Processed 2280 / 6000 documents...\n",
      "Processed 2285 / 6000 documents...\n",
      "Processed 2290 / 6000 documents...\n",
      "Processed 2295 / 6000 documents...\n",
      "Processed 2300 / 6000 documents...\n",
      "Processed 2305 / 6000 documents...\n",
      "Processed 2310 / 6000 documents...\n",
      "Processed 2315 / 6000 documents...\n",
      "Processed 2320 / 6000 documents...\n",
      "Processed 2325 / 6000 documents...\n",
      "Processed 2330 / 6000 documents...\n",
      "Processed 2335 / 6000 documents...\n",
      "Processed 2340 / 6000 documents...\n",
      "Processed 2345 / 6000 documents...\n",
      "Processed 2350 / 6000 documents...\n",
      "Processed 2355 / 6000 documents...\n",
      "Processed 2360 / 6000 documents...\n",
      "Processed 2365 / 6000 documents...\n",
      "Processed 2370 / 6000 documents...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2375 / 6000 documents...\n",
      "Processed 2380 / 6000 documents...\n",
      "Processed 2385 / 6000 documents...\n",
      "Processed 2390 / 6000 documents...\n",
      "Processed 2395 / 6000 documents...\n",
      "Processed 2400 / 6000 documents...\n",
      "Processed 2405 / 6000 documents...\n",
      "Processed 2410 / 6000 documents...\n",
      "Processed 2415 / 6000 documents...\n",
      "Processed 2420 / 6000 documents...\n",
      "Processed 2425 / 6000 documents...\n",
      "Processed 2430 / 6000 documents...\n",
      "Processed 2435 / 6000 documents...\n",
      "Processed 2440 / 6000 documents...\n",
      "Processed 2445 / 6000 documents...\n",
      "Processed 2450 / 6000 documents...\n",
      "Processed 2455 / 6000 documents...\n",
      "Processed 2460 / 6000 documents...\n",
      "Processed 2465 / 6000 documents...\n",
      "Processed 2470 / 6000 documents...\n",
      "Processed 2475 / 6000 documents...\n",
      "Processed 2480 / 6000 documents...\n",
      "Processed 2485 / 6000 documents...\n",
      "Processed 2490 / 6000 documents...\n",
      "Processed 2495 / 6000 documents...\n",
      "Processed 2500 / 6000 documents...\n",
      "Processed 2505 / 6000 documents...\n",
      "Processed 2510 / 6000 documents...\n",
      "Processed 2515 / 6000 documents...\n",
      "Processed 2520 / 6000 documents...\n",
      "Processed 2525 / 6000 documents...\n",
      "Processed 2530 / 6000 documents...\n",
      "Processed 2535 / 6000 documents...\n",
      "Processed 2540 / 6000 documents...\n",
      "Processed 2545 / 6000 documents...\n",
      "Processed 2550 / 6000 documents...\n",
      "Processed 2555 / 6000 documents...\n",
      "Processed 2560 / 6000 documents...\n",
      "Processed 2565 / 6000 documents...\n",
      "Processed 2570 / 6000 documents...\n",
      "Processed 2575 / 6000 documents...\n",
      "Processed 2580 / 6000 documents...\n",
      "Processed 2585 / 6000 documents...\n",
      "Processed 2590 / 6000 documents...\n",
      "Processed 2595 / 6000 documents...\n",
      "Processed 2600 / 6000 documents...\n",
      "Processed 2605 / 6000 documents...\n",
      "Processed 2610 / 6000 documents...\n",
      "Processed 2615 / 6000 documents...\n",
      "Processed 2620 / 6000 documents...\n",
      "Processed 2625 / 6000 documents...\n",
      "Processed 2630 / 6000 documents...\n",
      "Processed 2635 / 6000 documents...\n",
      "Processed 2640 / 6000 documents...\n",
      "Processed 2645 / 6000 documents...\n",
      "Processed 2650 / 6000 documents...\n",
      "Processed 2655 / 6000 documents...\n",
      "Processed 2660 / 6000 documents...\n",
      "Processed 2665 / 6000 documents...\n",
      "Processed 2670 / 6000 documents...\n",
      "Processed 2675 / 6000 documents...\n",
      "Processed 2680 / 6000 documents...\n",
      "Processed 2685 / 6000 documents...\n",
      "Processed 2690 / 6000 documents...\n",
      "Processed 2695 / 6000 documents...\n",
      "Processed 2700 / 6000 documents...\n",
      "Processed 2705 / 6000 documents...\n",
      "Processed 2710 / 6000 documents...\n",
      "Processed 2715 / 6000 documents...\n",
      "Processed 2720 / 6000 documents...\n",
      "Processed 2725 / 6000 documents...\n",
      "Processed 2730 / 6000 documents...\n",
      "Processed 2735 / 6000 documents...\n",
      "Processed 2740 / 6000 documents...\n",
      "Processed 2745 / 6000 documents...\n",
      "Processed 2750 / 6000 documents...\n",
      "Processed 2755 / 6000 documents...\n",
      "Processed 2760 / 6000 documents...\n",
      "Processed 2765 / 6000 documents...\n",
      "Processed 2770 / 6000 documents...\n",
      "Processed 2775 / 6000 documents...\n",
      "Processed 2780 / 6000 documents...\n",
      "Processed 2785 / 6000 documents...\n",
      "Processed 2790 / 6000 documents...\n",
      "Processed 2795 / 6000 documents...\n",
      "Processed 2800 / 6000 documents...\n",
      "Processed 2805 / 6000 documents...\n",
      "Processed 2810 / 6000 documents...\n",
      "Processed 2815 / 6000 documents...\n",
      "Processed 2820 / 6000 documents...\n",
      "Processed 2825 / 6000 documents...\n",
      "Processed 2830 / 6000 documents...\n",
      "Processed 2835 / 6000 documents...\n",
      "Processed 2840 / 6000 documents...\n",
      "Processed 2845 / 6000 documents...\n",
      "Processed 2850 / 6000 documents...\n",
      "Processed 2855 / 6000 documents...\n",
      "Processed 2860 / 6000 documents...\n",
      "Processed 2865 / 6000 documents...\n",
      "Processed 2870 / 6000 documents...\n",
      "Processed 2875 / 6000 documents...\n",
      "Processed 2880 / 6000 documents...\n",
      "Processed 2885 / 6000 documents...\n",
      "Processed 2890 / 6000 documents...\n",
      "Processed 2895 / 6000 documents...\n",
      "Processed 2900 / 6000 documents...\n",
      "Processed 2905 / 6000 documents...\n",
      "Processed 2910 / 6000 documents...\n",
      "Processed 2915 / 6000 documents...\n",
      "Processed 2920 / 6000 documents...\n",
      "Processed 2925 / 6000 documents...\n",
      "Processed 2930 / 6000 documents...\n",
      "Processed 2935 / 6000 documents...\n",
      "Processed 2940 / 6000 documents...\n",
      "Processed 2945 / 6000 documents...\n",
      "Processed 2950 / 6000 documents...\n",
      "Processed 2955 / 6000 documents...\n",
      "Processed 2960 / 6000 documents...\n",
      "Processed 2965 / 6000 documents...\n",
      "Processed 2970 / 6000 documents...\n",
      "Processed 2975 / 6000 documents...\n",
      "Processed 2980 / 6000 documents...\n",
      "Processed 2985 / 6000 documents...\n",
      "Processed 2990 / 6000 documents...\n",
      "Processed 2995 / 6000 documents...\n",
      "Processed 3000 / 6000 documents...\n",
      "Processed 3005 / 6000 documents...\n",
      "Processed 3010 / 6000 documents...\n",
      "Processed 3015 / 6000 documents...\n",
      "Processed 3020 / 6000 documents...\n",
      "Processed 3025 / 6000 documents...\n",
      "Processed 3030 / 6000 documents...\n",
      "Processed 3035 / 6000 documents...\n",
      "Processed 3040 / 6000 documents...\n",
      "Processed 3045 / 6000 documents...\n",
      "Processed 3050 / 6000 documents...\n",
      "Processed 3055 / 6000 documents...\n",
      "Processed 3060 / 6000 documents...\n",
      "Processed 3065 / 6000 documents...\n",
      "Processed 3070 / 6000 documents...\n",
      "Processed 3075 / 6000 documents...\n",
      "Processed 3080 / 6000 documents...\n",
      "Processed 3085 / 6000 documents...\n",
      "Processed 3090 / 6000 documents...\n",
      "Processed 3095 / 6000 documents...\n",
      "Processed 3100 / 6000 documents...\n",
      "Processed 3105 / 6000 documents...\n",
      "Processed 3110 / 6000 documents...\n",
      "Processed 3115 / 6000 documents...\n",
      "Processed 3120 / 6000 documents...\n",
      "Processed 3125 / 6000 documents...\n",
      "Processed 3130 / 6000 documents...\n",
      "Processed 3135 / 6000 documents...\n",
      "Processed 3140 / 6000 documents...\n",
      "Processed 3145 / 6000 documents...\n",
      "Processed 3150 / 6000 documents...\n",
      "Processed 3155 / 6000 documents...\n",
      "Processed 3160 / 6000 documents...\n",
      "Processed 3165 / 6000 documents...\n",
      "Processed 3170 / 6000 documents...\n",
      "Processed 3175 / 6000 documents...\n",
      "Processed 3180 / 6000 documents...\n",
      "Processed 3185 / 6000 documents...\n",
      "Processed 3190 / 6000 documents...\n",
      "Processed 3195 / 6000 documents...\n",
      "Processed 3200 / 6000 documents...\n",
      "Processed 3205 / 6000 documents...\n",
      "Processed 3210 / 6000 documents...\n",
      "Processed 3215 / 6000 documents...\n",
      "Processed 3220 / 6000 documents...\n",
      "Processed 3225 / 6000 documents...\n",
      "Processed 3230 / 6000 documents...\n",
      "Processed 3235 / 6000 documents...\n",
      "Processed 3240 / 6000 documents...\n",
      "Processed 3245 / 6000 documents...\n",
      "Processed 3250 / 6000 documents...\n",
      "Processed 3255 / 6000 documents...\n",
      "Processed 3260 / 6000 documents...\n",
      "Processed 3265 / 6000 documents...\n",
      "Processed 3270 / 6000 documents...\n",
      "Processed 3275 / 6000 documents...\n",
      "Processed 3280 / 6000 documents...\n",
      "Processed 3285 / 6000 documents...\n",
      "Processed 3290 / 6000 documents...\n",
      "Processed 3295 / 6000 documents...\n",
      "Processed 3300 / 6000 documents...\n",
      "Processed 3305 / 6000 documents...\n",
      "Processed 3310 / 6000 documents...\n",
      "Processed 3315 / 6000 documents...\n",
      "Processed 3320 / 6000 documents...\n",
      "Processed 3325 / 6000 documents...\n",
      "Processed 3330 / 6000 documents...\n",
      "Processed 3335 / 6000 documents...\n",
      "Processed 3340 / 6000 documents...\n",
      "Processed 3345 / 6000 documents...\n",
      "Processed 3350 / 6000 documents...\n",
      "Processed 3355 / 6000 documents...\n",
      "Processed 3360 / 6000 documents...\n",
      "Processed 3365 / 6000 documents...\n",
      "Processed 3370 / 6000 documents...\n",
      "Processed 3375 / 6000 documents...\n",
      "Processed 3380 / 6000 documents...\n",
      "Processed 3385 / 6000 documents...\n",
      "Processed 3390 / 6000 documents...\n",
      "Processed 3395 / 6000 documents...\n",
      "Processed 3400 / 6000 documents...\n",
      "Processed 3405 / 6000 documents...\n",
      "Processed 3410 / 6000 documents...\n",
      "Processed 3415 / 6000 documents...\n",
      "Processed 3420 / 6000 documents...\n",
      "Processed 3425 / 6000 documents...\n",
      "Processed 3430 / 6000 documents...\n",
      "Processed 3435 / 6000 documents...\n",
      "Processed 3440 / 6000 documents...\n",
      "Processed 3445 / 6000 documents...\n",
      "Processed 3450 / 6000 documents...\n",
      "Processed 3455 / 6000 documents...\n",
      "Processed 3460 / 6000 documents...\n",
      "Processed 3465 / 6000 documents...\n",
      "Processed 3470 / 6000 documents...\n",
      "Processed 3475 / 6000 documents...\n",
      "Processed 3480 / 6000 documents...\n",
      "Processed 3485 / 6000 documents...\n",
      "Processed 3490 / 6000 documents...\n",
      "Processed 3495 / 6000 documents...\n",
      "Processed 3500 / 6000 documents...\n",
      "Processed 3505 / 6000 documents...\n",
      "Processed 3510 / 6000 documents...\n",
      "Processed 3515 / 6000 documents...\n",
      "Processed 3520 / 6000 documents...\n",
      "Processed 3525 / 6000 documents...\n",
      "Processed 3530 / 6000 documents...\n",
      "Processed 3535 / 6000 documents...\n",
      "Processed 3540 / 6000 documents...\n",
      "Processed 3545 / 6000 documents...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3550 / 6000 documents...\n",
      "Processed 3555 / 6000 documents...\n",
      "Processed 3560 / 6000 documents...\n",
      "Processed 3565 / 6000 documents...\n",
      "Processed 3570 / 6000 documents...\n",
      "Processed 3575 / 6000 documents...\n",
      "Processed 3580 / 6000 documents...\n",
      "Processed 3585 / 6000 documents...\n",
      "Processed 3590 / 6000 documents...\n",
      "Processed 3595 / 6000 documents...\n",
      "Processed 3600 / 6000 documents...\n",
      "Processed 3605 / 6000 documents...\n",
      "Processed 3610 / 6000 documents...\n",
      "Processed 3615 / 6000 documents...\n",
      "Processed 3620 / 6000 documents...\n",
      "Processed 3625 / 6000 documents...\n",
      "Processed 3630 / 6000 documents...\n",
      "Processed 3635 / 6000 documents...\n",
      "Processed 3640 / 6000 documents...\n",
      "Processed 3645 / 6000 documents...\n",
      "Processed 3650 / 6000 documents...\n",
      "Processed 3655 / 6000 documents...\n",
      "Processed 3660 / 6000 documents...\n",
      "Processed 3665 / 6000 documents...\n",
      "Processed 3670 / 6000 documents...\n",
      "Processed 3675 / 6000 documents...\n",
      "Processed 3680 / 6000 documents...\n",
      "Processed 3685 / 6000 documents...\n",
      "Processed 3690 / 6000 documents...\n",
      "Processed 3695 / 6000 documents...\n",
      "Processed 3700 / 6000 documents...\n",
      "Processed 3705 / 6000 documents...\n",
      "Processed 3710 / 6000 documents...\n",
      "Processed 3715 / 6000 documents...\n",
      "Processed 3720 / 6000 documents...\n",
      "Processed 3725 / 6000 documents...\n",
      "Processed 3730 / 6000 documents...\n",
      "Processed 3735 / 6000 documents...\n",
      "Processed 3740 / 6000 documents...\n",
      "Processed 3745 / 6000 documents...\n",
      "Processed 3750 / 6000 documents...\n",
      "Processed 3755 / 6000 documents...\n",
      "Processed 3760 / 6000 documents...\n",
      "Processed 3765 / 6000 documents...\n",
      "Processed 3770 / 6000 documents...\n",
      "Processed 3775 / 6000 documents...\n",
      "Processed 3780 / 6000 documents...\n",
      "Processed 3785 / 6000 documents...\n",
      "Processed 3790 / 6000 documents...\n",
      "Processed 3795 / 6000 documents...\n",
      "Processed 3800 / 6000 documents...\n",
      "Processed 3805 / 6000 documents...\n",
      "Processed 3810 / 6000 documents...\n",
      "Processed 3815 / 6000 documents...\n",
      "Processed 3820 / 6000 documents...\n",
      "Processed 3825 / 6000 documents...\n",
      "Processed 3830 / 6000 documents...\n",
      "Processed 3835 / 6000 documents...\n",
      "Processed 3840 / 6000 documents...\n",
      "Processed 3845 / 6000 documents...\n",
      "Processed 3850 / 6000 documents...\n",
      "Processed 3855 / 6000 documents...\n",
      "Processed 3860 / 6000 documents...\n",
      "Processed 3865 / 6000 documents...\n",
      "Processed 3870 / 6000 documents...\n",
      "Processed 3875 / 6000 documents...\n",
      "Processed 3880 / 6000 documents...\n",
      "Processed 3885 / 6000 documents...\n",
      "Processed 3890 / 6000 documents...\n",
      "Processed 3895 / 6000 documents...\n",
      "Processed 3900 / 6000 documents...\n",
      "Processed 3905 / 6000 documents...\n",
      "Processed 3910 / 6000 documents...\n",
      "Processed 3915 / 6000 documents...\n",
      "Processed 3920 / 6000 documents...\n",
      "Processed 3925 / 6000 documents...\n",
      "Processed 3930 / 6000 documents...\n",
      "Processed 3935 / 6000 documents...\n",
      "Processed 3940 / 6000 documents...\n",
      "Processed 3945 / 6000 documents...\n",
      "Processed 3950 / 6000 documents...\n",
      "Processed 3955 / 6000 documents...\n",
      "Processed 3960 / 6000 documents...\n",
      "Processed 3965 / 6000 documents...\n",
      "Processed 3970 / 6000 documents...\n",
      "Processed 3975 / 6000 documents...\n",
      "Processed 3980 / 6000 documents...\n",
      "Processed 3985 / 6000 documents...\n",
      "Processed 3990 / 6000 documents...\n",
      "Processed 3995 / 6000 documents...\n",
      "Processed 4000 / 6000 documents...\n",
      "Processed 4005 / 6000 documents...\n",
      "Processed 4010 / 6000 documents...\n",
      "Processed 4015 / 6000 documents...\n",
      "Processed 4020 / 6000 documents...\n",
      "Processed 4025 / 6000 documents...\n",
      "Processed 4030 / 6000 documents...\n",
      "Processed 4035 / 6000 documents...\n",
      "Processed 4040 / 6000 documents...\n",
      "Processed 4045 / 6000 documents...\n",
      "Processed 4050 / 6000 documents...\n",
      "Processed 4055 / 6000 documents...\n",
      "Processed 4060 / 6000 documents...\n",
      "Processed 4065 / 6000 documents...\n",
      "Processed 4070 / 6000 documents...\n",
      "Processed 4075 / 6000 documents...\n",
      "Processed 4080 / 6000 documents...\n",
      "Processed 4085 / 6000 documents...\n",
      "Processed 4090 / 6000 documents...\n",
      "Processed 4095 / 6000 documents...\n",
      "Processed 4100 / 6000 documents...\n",
      "Processed 4105 / 6000 documents...\n",
      "Processed 4110 / 6000 documents...\n",
      "Processed 4115 / 6000 documents...\n",
      "Processed 4120 / 6000 documents...\n",
      "Processed 4125 / 6000 documents...\n",
      "Processed 4130 / 6000 documents...\n",
      "Processed 4135 / 6000 documents...\n",
      "Processed 4140 / 6000 documents...\n",
      "Processed 4145 / 6000 documents...\n",
      "Processed 4150 / 6000 documents...\n",
      "Processed 4155 / 6000 documents...\n",
      "Processed 4160 / 6000 documents...\n",
      "Processed 4165 / 6000 documents...\n",
      "Processed 4170 / 6000 documents...\n",
      "Processed 4175 / 6000 documents...\n",
      "Processed 4180 / 6000 documents...\n",
      "Processed 4185 / 6000 documents...\n",
      "Processed 4190 / 6000 documents...\n",
      "Processed 4195 / 6000 documents...\n",
      "Processed 4200 / 6000 documents...\n",
      "Processed 4205 / 6000 documents...\n",
      "Processed 4210 / 6000 documents...\n",
      "Processed 4215 / 6000 documents...\n",
      "Processed 4220 / 6000 documents...\n",
      "Processed 4225 / 6000 documents...\n",
      "Processed 4230 / 6000 documents...\n",
      "Processed 4235 / 6000 documents...\n",
      "Processed 4240 / 6000 documents...\n",
      "Processed 4245 / 6000 documents...\n",
      "Processed 4250 / 6000 documents...\n",
      "Processed 4255 / 6000 documents...\n",
      "Processed 4260 / 6000 documents...\n",
      "Processed 4265 / 6000 documents...\n",
      "Processed 4270 / 6000 documents...\n",
      "Processed 4275 / 6000 documents...\n",
      "Processed 4280 / 6000 documents...\n",
      "Processed 4285 / 6000 documents...\n",
      "Processed 4290 / 6000 documents...\n",
      "Processed 4295 / 6000 documents...\n",
      "Processed 4300 / 6000 documents...\n",
      "Processed 4305 / 6000 documents...\n",
      "Processed 4310 / 6000 documents...\n",
      "Processed 4315 / 6000 documents...\n",
      "Processed 4320 / 6000 documents...\n",
      "Processed 4325 / 6000 documents...\n",
      "Processed 4330 / 6000 documents...\n",
      "Processed 4335 / 6000 documents...\n",
      "Processed 4340 / 6000 documents...\n",
      "Processed 4345 / 6000 documents...\n",
      "Processed 4350 / 6000 documents...\n",
      "Processed 4355 / 6000 documents...\n",
      "Processed 4360 / 6000 documents...\n",
      "Processed 4365 / 6000 documents...\n",
      "Processed 4370 / 6000 documents...\n",
      "Processed 4375 / 6000 documents...\n",
      "Processed 4380 / 6000 documents...\n",
      "Processed 4385 / 6000 documents...\n",
      "Processed 4390 / 6000 documents...\n",
      "Processed 4395 / 6000 documents...\n",
      "Processed 4400 / 6000 documents...\n",
      "Processed 4405 / 6000 documents...\n",
      "Processed 4410 / 6000 documents...\n",
      "Processed 4415 / 6000 documents...\n",
      "Processed 4420 / 6000 documents...\n",
      "Processed 4425 / 6000 documents...\n",
      "Processed 4430 / 6000 documents...\n",
      "Processed 4435 / 6000 documents...\n",
      "Processed 4440 / 6000 documents...\n",
      "Processed 4445 / 6000 documents...\n",
      "Processed 4450 / 6000 documents...\n",
      "Processed 4455 / 6000 documents...\n",
      "Processed 4460 / 6000 documents...\n",
      "Processed 4465 / 6000 documents...\n",
      "Processed 4470 / 6000 documents...\n",
      "Processed 4475 / 6000 documents...\n",
      "Processed 4480 / 6000 documents...\n",
      "Processed 4485 / 6000 documents...\n",
      "Processed 4490 / 6000 documents...\n",
      "Processed 4495 / 6000 documents...\n",
      "Processed 4500 / 6000 documents...\n",
      "Processed 4505 / 6000 documents...\n",
      "Processed 4510 / 6000 documents...\n",
      "Processed 4515 / 6000 documents...\n",
      "Processed 4520 / 6000 documents...\n",
      "Processed 4525 / 6000 documents...\n",
      "Processed 4530 / 6000 documents...\n",
      "Processed 4535 / 6000 documents...\n",
      "Processed 4540 / 6000 documents...\n",
      "Processed 4545 / 6000 documents...\n",
      "Processed 4550 / 6000 documents...\n",
      "Processed 4555 / 6000 documents...\n",
      "Processed 4560 / 6000 documents...\n",
      "Processed 4565 / 6000 documents...\n",
      "Processed 4570 / 6000 documents...\n",
      "Processed 4575 / 6000 documents...\n",
      "Processed 4580 / 6000 documents...\n",
      "Processed 4585 / 6000 documents...\n",
      "Processed 4590 / 6000 documents...\n",
      "Processed 4595 / 6000 documents...\n",
      "Processed 4600 / 6000 documents...\n",
      "Processed 4605 / 6000 documents...\n",
      "Processed 4610 / 6000 documents...\n",
      "Processed 4615 / 6000 documents...\n",
      "Processed 4620 / 6000 documents...\n",
      "Processed 4625 / 6000 documents...\n",
      "Processed 4630 / 6000 documents...\n",
      "Processed 4635 / 6000 documents...\n",
      "Processed 4640 / 6000 documents...\n",
      "Processed 4645 / 6000 documents...\n",
      "Processed 4650 / 6000 documents...\n",
      "Processed 4655 / 6000 documents...\n",
      "Processed 4660 / 6000 documents...\n",
      "Processed 4665 / 6000 documents...\n",
      "Processed 4670 / 6000 documents...\n",
      "Processed 4675 / 6000 documents...\n",
      "Processed 4680 / 6000 documents...\n",
      "Processed 4685 / 6000 documents...\n",
      "Processed 4690 / 6000 documents...\n",
      "Processed 4695 / 6000 documents...\n",
      "Processed 4700 / 6000 documents...\n",
      "Processed 4705 / 6000 documents...\n",
      "Processed 4710 / 6000 documents...\n",
      "Processed 4715 / 6000 documents...\n",
      "Processed 4720 / 6000 documents...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4725 / 6000 documents...\n",
      "Processed 4730 / 6000 documents...\n",
      "Processed 4735 / 6000 documents...\n",
      "Processed 4740 / 6000 documents...\n",
      "Processed 4745 / 6000 documents...\n",
      "Processed 4750 / 6000 documents...\n",
      "Processed 4755 / 6000 documents...\n",
      "Processed 4760 / 6000 documents...\n",
      "Processed 4765 / 6000 documents...\n",
      "Processed 4770 / 6000 documents...\n",
      "Processed 4775 / 6000 documents...\n",
      "Processed 4780 / 6000 documents...\n",
      "Processed 4785 / 6000 documents...\n",
      "Processed 4790 / 6000 documents...\n",
      "Processed 4795 / 6000 documents...\n",
      "Processed 4800 / 6000 documents...\n",
      "Processed 4805 / 6000 documents...\n",
      "Processed 4810 / 6000 documents...\n",
      "Processed 4815 / 6000 documents...\n",
      "Processed 4820 / 6000 documents...\n",
      "Processed 4825 / 6000 documents...\n",
      "Processed 4830 / 6000 documents...\n",
      "Processed 4835 / 6000 documents...\n",
      "Processed 4840 / 6000 documents...\n",
      "Processed 4845 / 6000 documents...\n",
      "Processed 4850 / 6000 documents...\n",
      "Processed 4855 / 6000 documents...\n",
      "Processed 4860 / 6000 documents...\n",
      "Processed 4865 / 6000 documents...\n",
      "Processed 4870 / 6000 documents...\n",
      "Processed 4875 / 6000 documents...\n",
      "Processed 4880 / 6000 documents...\n",
      "Processed 4885 / 6000 documents...\n",
      "Processed 4890 / 6000 documents...\n",
      "Processed 4895 / 6000 documents...\n",
      "Processed 4900 / 6000 documents...\n",
      "Processed 4905 / 6000 documents...\n",
      "Processed 4910 / 6000 documents...\n",
      "Processed 4915 / 6000 documents...\n",
      "Processed 4920 / 6000 documents...\n",
      "Processed 4925 / 6000 documents...\n",
      "Processed 4930 / 6000 documents...\n",
      "Processed 4935 / 6000 documents...\n",
      "Processed 4940 / 6000 documents...\n",
      "Processed 4945 / 6000 documents...\n",
      "Processed 4950 / 6000 documents...\n",
      "Processed 4955 / 6000 documents...\n",
      "Processed 4960 / 6000 documents...\n",
      "Processed 4965 / 6000 documents...\n",
      "Processed 4970 / 6000 documents...\n",
      "Processed 4975 / 6000 documents...\n",
      "Processed 4980 / 6000 documents...\n",
      "Processed 4985 / 6000 documents...\n",
      "Processed 4990 / 6000 documents...\n",
      "Processed 4995 / 6000 documents...\n",
      "Processed 5000 / 6000 documents...\n",
      "Processed 5005 / 6000 documents...\n",
      "Processed 5010 / 6000 documents...\n",
      "Processed 5015 / 6000 documents...\n",
      "Processed 5020 / 6000 documents...\n",
      "Processed 5025 / 6000 documents...\n",
      "Processed 5030 / 6000 documents...\n",
      "Processed 5035 / 6000 documents...\n",
      "Processed 5040 / 6000 documents...\n",
      "Processed 5045 / 6000 documents...\n",
      "Processed 5050 / 6000 documents...\n",
      "Processed 5055 / 6000 documents...\n",
      "Processed 5060 / 6000 documents...\n",
      "Processed 5065 / 6000 documents...\n",
      "Processed 5070 / 6000 documents...\n",
      "Processed 5075 / 6000 documents...\n",
      "Processed 5080 / 6000 documents...\n",
      "Processed 5085 / 6000 documents...\n",
      "Processed 5090 / 6000 documents...\n",
      "Processed 5095 / 6000 documents...\n",
      "Processed 5100 / 6000 documents...\n",
      "Processed 5105 / 6000 documents...\n",
      "Processed 5110 / 6000 documents...\n",
      "Processed 5115 / 6000 documents...\n",
      "Processed 5120 / 6000 documents...\n",
      "Processed 5125 / 6000 documents...\n",
      "Processed 5130 / 6000 documents...\n",
      "Processed 5135 / 6000 documents...\n",
      "Processed 5140 / 6000 documents...\n",
      "Processed 5145 / 6000 documents...\n",
      "Processed 5150 / 6000 documents...\n",
      "Processed 5155 / 6000 documents...\n",
      "Processed 5160 / 6000 documents...\n",
      "Processed 5165 / 6000 documents...\n",
      "Processed 5170 / 6000 documents...\n",
      "Processed 5175 / 6000 documents...\n",
      "Processed 5180 / 6000 documents...\n",
      "Processed 5185 / 6000 documents...\n",
      "Processed 5190 / 6000 documents...\n",
      "Processed 5195 / 6000 documents...\n",
      "Processed 5200 / 6000 documents...\n",
      "Processed 5205 / 6000 documents...\n",
      "Processed 5210 / 6000 documents...\n",
      "Processed 5215 / 6000 documents...\n",
      "Processed 5220 / 6000 documents...\n",
      "Processed 5225 / 6000 documents...\n",
      "Processed 5230 / 6000 documents...\n",
      "Processed 5235 / 6000 documents...\n",
      "Processed 5240 / 6000 documents...\n",
      "Processed 5245 / 6000 documents...\n",
      "Processed 5250 / 6000 documents...\n",
      "Processed 5255 / 6000 documents...\n",
      "Processed 5260 / 6000 documents...\n",
      "Processed 5265 / 6000 documents...\n",
      "Processed 5270 / 6000 documents...\n",
      "Processed 5275 / 6000 documents...\n",
      "Processed 5280 / 6000 documents...\n",
      "Processed 5285 / 6000 documents...\n",
      "Processed 5290 / 6000 documents...\n",
      "Processed 5295 / 6000 documents...\n",
      "Processed 5300 / 6000 documents...\n",
      "Processed 5305 / 6000 documents...\n",
      "Processed 5310 / 6000 documents...\n",
      "Processed 5315 / 6000 documents...\n",
      "Processed 5320 / 6000 documents...\n",
      "Processed 5325 / 6000 documents...\n",
      "Processed 5330 / 6000 documents...\n",
      "Processed 5335 / 6000 documents...\n",
      "Processed 5340 / 6000 documents...\n",
      "Processed 5345 / 6000 documents...\n",
      "Processed 5350 / 6000 documents...\n",
      "Processed 5355 / 6000 documents...\n",
      "Processed 5360 / 6000 documents...\n",
      "Processed 5365 / 6000 documents...\n",
      "Processed 5370 / 6000 documents...\n",
      "Processed 5375 / 6000 documents...\n",
      "Processed 5380 / 6000 documents...\n",
      "Processed 5385 / 6000 documents...\n",
      "Processed 5390 / 6000 documents...\n",
      "Processed 5395 / 6000 documents...\n",
      "Processed 5400 / 6000 documents...\n",
      "Processed 5405 / 6000 documents...\n",
      "Processed 5410 / 6000 documents...\n",
      "Processed 5415 / 6000 documents...\n",
      "Processed 5420 / 6000 documents...\n",
      "Processed 5425 / 6000 documents...\n",
      "Processed 5430 / 6000 documents...\n",
      "Processed 5435 / 6000 documents...\n",
      "Processed 5440 / 6000 documents...\n",
      "Processed 5445 / 6000 documents...\n",
      "Processed 5450 / 6000 documents...\n",
      "Processed 5455 / 6000 documents...\n",
      "Processed 5460 / 6000 documents...\n",
      "Processed 5465 / 6000 documents...\n",
      "Processed 5470 / 6000 documents...\n",
      "Processed 5475 / 6000 documents...\n",
      "Processed 5480 / 6000 documents...\n",
      "Processed 5485 / 6000 documents...\n",
      "Processed 5490 / 6000 documents...\n",
      "Processed 5495 / 6000 documents...\n",
      "Processed 5500 / 6000 documents...\n",
      "Processed 5505 / 6000 documents...\n",
      "Processed 5510 / 6000 documents...\n",
      "Processed 5515 / 6000 documents...\n",
      "Processed 5520 / 6000 documents...\n",
      "Processed 5525 / 6000 documents...\n",
      "Processed 5530 / 6000 documents...\n",
      "Processed 5535 / 6000 documents...\n",
      "Processed 5540 / 6000 documents...\n",
      "Processed 5545 / 6000 documents...\n",
      "Processed 5550 / 6000 documents...\n",
      "Processed 5555 / 6000 documents...\n",
      "Processed 5560 / 6000 documents...\n",
      "Processed 5565 / 6000 documents...\n",
      "Processed 5570 / 6000 documents...\n",
      "Processed 5575 / 6000 documents...\n",
      "Processed 5580 / 6000 documents...\n",
      "Processed 5585 / 6000 documents...\n",
      "Processed 5590 / 6000 documents...\n",
      "Processed 5595 / 6000 documents...\n",
      "Processed 5600 / 6000 documents...\n",
      "Processed 5605 / 6000 documents...\n",
      "Processed 5610 / 6000 documents...\n",
      "Processed 5615 / 6000 documents...\n",
      "Processed 5620 / 6000 documents...\n",
      "Processed 5625 / 6000 documents...\n",
      "Processed 5630 / 6000 documents...\n",
      "Processed 5635 / 6000 documents...\n",
      "Processed 5640 / 6000 documents...\n",
      "Processed 5645 / 6000 documents...\n",
      "Processed 5650 / 6000 documents...\n",
      "Processed 5655 / 6000 documents...\n",
      "Processed 5660 / 6000 documents...\n",
      "Processed 5665 / 6000 documents...\n",
      "Processed 5670 / 6000 documents...\n",
      "Processed 5675 / 6000 documents...\n",
      "Processed 5680 / 6000 documents...\n",
      "Processed 5685 / 6000 documents...\n",
      "Processed 5690 / 6000 documents...\n",
      "Processed 5695 / 6000 documents...\n",
      "Processed 5700 / 6000 documents...\n",
      "Processed 5705 / 6000 documents...\n",
      "Processed 5710 / 6000 documents...\n",
      "Processed 5715 / 6000 documents...\n",
      "Processed 5720 / 6000 documents...\n",
      "Processed 5725 / 6000 documents...\n",
      "Processed 5730 / 6000 documents...\n",
      "Processed 5735 / 6000 documents...\n",
      "Processed 5740 / 6000 documents...\n",
      "Processed 5745 / 6000 documents...\n",
      "Processed 5750 / 6000 documents...\n",
      "Processed 5755 / 6000 documents...\n",
      "Processed 5760 / 6000 documents...\n",
      "Processed 5765 / 6000 documents...\n",
      "Processed 5770 / 6000 documents...\n",
      "Processed 5775 / 6000 documents...\n",
      "Processed 5780 / 6000 documents...\n",
      "Processed 5785 / 6000 documents...\n",
      "Processed 5790 / 6000 documents...\n",
      "Processed 5795 / 6000 documents...\n",
      "Processed 5800 / 6000 documents...\n",
      "Processed 5805 / 6000 documents...\n",
      "Processed 5810 / 6000 documents...\n",
      "Processed 5815 / 6000 documents...\n",
      "Processed 5820 / 6000 documents...\n",
      "Processed 5825 / 6000 documents...\n",
      "Processed 5830 / 6000 documents...\n",
      "Processed 5835 / 6000 documents...\n",
      "Processed 5840 / 6000 documents...\n",
      "Processed 5845 / 6000 documents...\n",
      "Processed 5850 / 6000 documents...\n",
      "Processed 5855 / 6000 documents...\n",
      "Processed 5860 / 6000 documents...\n",
      "Processed 5865 / 6000 documents...\n",
      "Processed 5870 / 6000 documents...\n",
      "Processed 5875 / 6000 documents...\n",
      "Processed 5880 / 6000 documents...\n",
      "Processed 5885 / 6000 documents...\n",
      "Processed 5890 / 6000 documents...\n",
      "Processed 5895 / 6000 documents...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5900 / 6000 documents...\n",
      "Processed 5905 / 6000 documents...\n",
      "Processed 5910 / 6000 documents...\n",
      "Processed 5915 / 6000 documents...\n",
      "Processed 5920 / 6000 documents...\n",
      "Processed 5925 / 6000 documents...\n",
      "Processed 5930 / 6000 documents...\n",
      "Processed 5935 / 6000 documents...\n",
      "Processed 5940 / 6000 documents...\n",
      "Processed 5945 / 6000 documents...\n",
      "Processed 5950 / 6000 documents...\n",
      "Processed 5955 / 6000 documents...\n",
      "Processed 5960 / 6000 documents...\n",
      "Processed 5965 / 6000 documents...\n",
      "Processed 5970 / 6000 documents...\n",
      "Processed 5975 / 6000 documents...\n",
      "Processed 5980 / 6000 documents...\n",
      "Processed 5985 / 6000 documents...\n",
      "Processed 5990 / 6000 documents...\n",
      "Processed 5995 / 6000 documents...\n",
      "Processed 6000 / 6000 documents...\n",
      "\n",
      "============================================================\n",
      "   AZURE PII EVALUATION RESULTS BY OBFUSCATION TYPE   \n",
      "============================================================\n",
      "\n",
      "[1-SPACE]\n",
      "  Ground Truth Entities: 2808 | Predicted Entities: 1396\n",
      "  - STRICT MATCHING:\n",
      "      Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n",
      "  - SOFT MATCHING (1:1 Greedy Overlap):\n",
      "      Precision: 0.0530 | Recall: 0.0264 | F1: 0.0352\n",
      "------------------------------------------------------------\n",
      "\n",
      "[5-SPACE]\n",
      "  Ground Truth Entities: 2808 | Predicted Entities: 1987\n",
      "  - STRICT MATCHING:\n",
      "      Precision: 0.1651 | Recall: 0.1168 | F1: 0.1368\n",
      "  - SOFT MATCHING (1:1 Greedy Overlap):\n",
      "      Precision: 0.4892 | Recall: 0.3462 | F1: 0.4054\n",
      "------------------------------------------------------------\n",
      "\n",
      "[NONE]\n",
      "  Ground Truth Entities: 2808 | Predicted Entities: 2698\n",
      "  - STRICT MATCHING:\n",
      "      Precision: 0.5615 | Recall: 0.5395 | F1: 0.5503\n",
      "  - SOFT MATCHING (1:1 Greedy Overlap):\n",
      "      Precision: 0.7031 | Recall: 0.6756 | F1: 0.6891\n",
      "------------------------------------------------------------\n",
      "\n",
      "[TEXTUALIZATION]\n",
      "  Ground Truth Entities: 2808 | Predicted Entities: 2297\n",
      "  - STRICT MATCHING:\n",
      "      Precision: 0.4188 | Recall: 0.3426 | F1: 0.3769\n",
      "  - SOFT MATCHING (1:1 Greedy Overlap):\n",
      "      Precision: 0.5612 | Recall: 0.4590 | F1: 0.5050\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def run_evaluation_by_obfuscation(dataset):\n",
    "    batch_size = 5\n",
    "    total_docs = len(dataset)\n",
    "    print(f\"Processing {total_docs} documents for Azure Evaluation...\\n\")\n",
    "    \n",
    "    # Dictionary to store our metrics, separated by obfuscation type\n",
    "    # Structure: { \"None\": {\"gt\": 0, \"pred\": 0, \"strict\": 0, \"soft\": 0}, ... }\n",
    "    metrics = defaultdict(lambda: {'total_gt': 0, 'total_pred': 0, 'strict_matched': 0, 'soft_matched': 0})\n",
    "    \n",
    "    for i in range(0, total_docs, batch_size):\n",
    "        batch = dataset[i:i + batch_size]\n",
    "        texts = [doc[\"full_text\"] for doc in batch]\n",
    "        \n",
    "        # Call Azure API\n",
    "        response = client.recognize_pii_entities(texts, language=\"en\")\n",
    "        \n",
    "        for doc_idx, result in enumerate(response):\n",
    "            # Extract the obfuscation type from the document's metadata\n",
    "            obf_type = batch[doc_idx][\"metadata\"][\"obfuscation_type\"]\n",
    "            \n",
    "            # --- 1. Get Ground Truth Tuples ---\n",
    "            doc_gt = set()\n",
    "            for span in batch[doc_idx][\"spans\"]:\n",
    "                mapped_type = AZURE_PII_MAPPING.get(span[\"entity_type\"], span[\"entity_type\"])\n",
    "                if mapped_type != 'O': \n",
    "                    doc_gt.add((mapped_type, span[\"start_position\"], span[\"end_position\"]))\n",
    "                    \n",
    "            metrics[obf_type]['total_gt'] += len(doc_gt)\n",
    "            \n",
    "            # Handle Azure API errors gracefully\n",
    "            if result.is_error:\n",
    "                continue\n",
    "                \n",
    "            # --- 2. Get Predicted Tuples ---\n",
    "            doc_pred = set()\n",
    "            for entity in result.entities:\n",
    "                doc_pred.add((entity.category, entity.offset, entity.offset + entity.length))\n",
    "                \n",
    "            metrics[obf_type]['total_pred'] += len(doc_pred)\n",
    "            \n",
    "            # --- 3. CALCULATE METRICS FOR THIS DOCUMENT ---\n",
    "            \n",
    "            # STRICT: Exact Matches\n",
    "            metrics[obf_type]['strict_matched'] += len(doc_gt.intersection(doc_pred))\n",
    "            \n",
    "            # SOFT: Greedy 1:1 Bipartite Matching\n",
    "            gt_list = list(doc_gt)\n",
    "            pred_list = list(doc_pred)\n",
    "            overlaps = []\n",
    "            \n",
    "            for gt_idx, gt in enumerate(gt_list):\n",
    "                gt_type, gt_start, gt_end = gt\n",
    "                for pred_idx, pred in enumerate(pred_list):\n",
    "                    pred_type, pred_start, pred_end = pred\n",
    "                    \n",
    "                    if gt_type == pred_type:\n",
    "                        overlap_length = min(gt_end, pred_end) - max(gt_start, pred_start)\n",
    "                        if overlap_length > 0:\n",
    "                            overlaps.append((overlap_length, gt_idx, pred_idx))\n",
    "                            \n",
    "            overlaps.sort(key=lambda x: x[0], reverse=True)\n",
    "            claimed_gts = set()\n",
    "            claimed_preds = set()\n",
    "            \n",
    "            for overlap_length, gt_idx, pred_idx in overlaps:\n",
    "                if gt_idx not in claimed_gts and pred_idx not in claimed_preds:\n",
    "                    claimed_gts.add(gt_idx)\n",
    "                    claimed_preds.add(pred_idx)\n",
    "                    metrics[obf_type]['soft_matched'] += 1\n",
    "                    \n",
    "        print(f\"Processed {min(i + batch_size, total_docs)} / {total_docs} documents...\")\n",
    "\n",
    "    # --- 4. FINALIZE MATH & PRINT RESULTS ---\n",
    "    def calc_f1(precision, recall):\n",
    "        return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"   AZURE PII EVALUATION RESULTS BY OBFUSCATION TYPE   \")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Sort the dictionary keys so the printout is consistent\n",
    "    for obf_type in sorted(metrics.keys()):\n",
    "        stats = metrics[obf_type]\n",
    "        total_gt = stats['total_gt']\n",
    "        total_pred = stats['total_pred']\n",
    "        \n",
    "        # Strict Math\n",
    "        strict_precision = stats['strict_matched'] / total_pred if total_pred > 0 else 0.0\n",
    "        strict_recall = stats['strict_matched'] / total_gt if total_gt > 0 else 0.0\n",
    "        strict_f1 = calc_f1(strict_precision, strict_recall)\n",
    "\n",
    "        # Soft Math\n",
    "        soft_precision = stats['soft_matched'] / total_pred if total_pred > 0 else 0.0\n",
    "        soft_recall = stats['soft_matched'] / total_gt if total_gt > 0 else 0.0\n",
    "        soft_f1 = calc_f1(soft_precision, soft_recall)\n",
    "\n",
    "        print(f\"\\n[{obf_type.upper()}]\")\n",
    "        print(f\"  Ground Truth Entities: {total_gt} | Predicted Entities: {total_pred}\")\n",
    "        print(\"  - STRICT MATCHING:\")\n",
    "        print(f\"      Precision: {strict_precision:.4f} | Recall: {strict_recall:.4f} | F1: {strict_f1:.4f}\")\n",
    "        print(\"  - SOFT MATCHING (1:1 Greedy Overlap):\")\n",
    "        print(f\"      Precision: {soft_precision:.4f} | Recall: {soft_recall:.4f} | F1: {soft_f1:.4f}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "run_evaluation_by_obfuscation(obfuscated_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432df56e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
