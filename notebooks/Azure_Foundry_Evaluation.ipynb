{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f8bcf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-textanalytics\n",
      "  Using cached azure_ai_textanalytics-5.3.0-py3-none-any.whl.metadata (82 kB)\n",
      "Collecting azure-identity\n",
      "  Using cached azure_identity-1.25.2-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting azure-core<2.0.0,>=1.24.0 (from azure-ai-textanalytics)\n",
      "  Using cached azure_core-1.38.2-py3-none-any.whl.metadata (48 kB)\n",
      "Collecting azure-common~=1.1 (from azure-ai-textanalytics)\n",
      "  Using cached azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting isodate<1.0.0,>=0.6.1 (from azure-ai-textanalytics)\n",
      "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from azure-ai-textanalytics) (4.14.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.32.3)\n",
      "Collecting cryptography>=2.5 (from azure-identity)\n",
      "  Downloading cryptography-46.0.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting msal>=1.31.0 (from azure-identity)\n",
      "  Using cached msal-1.35.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity)\n",
      "  Using cached msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=2.5->azure-identity)\n",
      "  Downloading cffi-2.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity) (2.21)\n",
      "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal>=1.31.0->azure-identity)\n",
      "  Downloading pyjwt-2.11.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2025.8.3)\n",
      "Using cached azure_ai_textanalytics-5.3.0-py3-none-any.whl (298 kB)\n",
      "Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Using cached azure_core-1.38.2-py3-none-any.whl (217 kB)\n",
      "Using cached isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Using cached azure_identity-1.25.2-py3-none-any.whl (191 kB)\n",
      "Downloading cryptography-46.0.5-cp38-abi3-macosx_10_9_universal2.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cffi-2.0.0-cp310-cp310-macosx_11_0_arm64.whl (180 kB)\n",
      "Using cached msal-1.35.0-py3-none-any.whl (120 kB)\n",
      "Downloading pyjwt-2.11.0-py3-none-any.whl (28 kB)\n",
      "Using cached msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: azure-common, PyJWT, isodate, cffi, cryptography, azure-core, azure-ai-textanalytics, msal, msal-extensions, azure-identity\n",
      "\u001b[2K  Attempting uninstall: cffi\n",
      "\u001b[2K    Found existing installation: cffi 1.15.1\n",
      "\u001b[2K    Uninstalling cffi-1.15.1:\n",
      "\u001b[2K      Successfully uninstalled cffi-1.15.1━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [cffi]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [azure-identity]m [azure-identity]alytics]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyJWT-2.11.0 azure-ai-textanalytics-5.3.0 azure-common-1.1.28 azure-core-1.38.2 azure-identity-1.25.2 cffi-2.0.0 cryptography-46.0.5 isodate-0.7.2 msal-1.35.0 msal-extensions-1.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-ai-textanalytics azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018c1224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.11.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting spacy-stanza\n",
      "  Downloading spacy_stanza-1.0.4-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting flair\n",
      "  Downloading flair-0.15.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting emoji (from stanza)\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (2.2.6)\n",
      "Requirement already satisfied: platformdirs in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (4.3.8)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (4.25.4)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (2.32.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (3.3)\n",
      "Collecting tomli (from stanza)\n",
      "  Downloading tomli-2.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (2.4.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from stanza) (4.66.5)\n",
      "Collecting udtools>=0.2.4 (from stanza)\n",
      "  Downloading udtools-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy-stanza) (3.8.11)\n",
      "Collecting stanza\n",
      "  Downloading stanza-1.6.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.24.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (63.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-stanza) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->stanza) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->stanza) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->stanza) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->stanza) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.0.0->spacy-stanza) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.1.5)\n",
      "Requirement already satisfied: typer>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.24.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from weasel<0.5.0,>=0.4.2->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from weasel<0.5.0,>=0.4.2->spacy<4.0.0,>=3.0.0->spacy-stanza) (7.5.1)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy<4.0.0,>=3.0.0->spacy-stanza) (1.16.0)\n",
      "Collecting boto3>=1.20.27 (from flair)\n",
      "  Downloading boto3-1.42.59-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting conllu<5.0.0,>=4.0 (from flair)\n",
      "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (1.2.14)\n",
      "Collecting ftfy>=6.1.0 (from flair)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting gdown>=4.4.0 (from flair)\n",
      "  Downloading gdown-5.2.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (0.24.6)\n",
      "Collecting langdetect>=1.0.9 (from flair)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (5.2.2)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (3.6.0)\n",
      "Collecting more-itertools>=8.13.0 (from flair)\n",
      "  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting mpld3>=0.3 (from flair)\n",
      "  Downloading mpld3-0.5.12-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pptree>=3.1 (from flair)\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (2.8.2)\n",
      "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
      "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (2023.10.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (1.7.2)\n",
      "Collecting segtok>=1.5.11 (from flair)\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.8.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair) (0.9.0)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
      "  Downloading transformer_smaller_training_vocab-0.4.2-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.25.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.44.1)\n",
      "Collecting wikipedia-api>=0.5.7 (from flair)\n",
      "  Downloading wikipedia_api-0.9.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bioc<3.0.0,>=2.0.0 (from flair)\n",
      "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading intervaltree-3.2.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting docopt (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.4.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.10.0->flair) (2023.12.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.2.0)\n",
      "Collecting botocore<1.43.0,>=1.42.59 (from boto3>=1.20.27->flair)\n",
      "  Downloading botocore-1.42.59-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
      "  Downloading jmespath-1.1.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3>=1.20.27->flair)\n",
      "  Downloading s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->flair) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ftfy>=6.1.0->flair) (0.2.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown>=4.4.0->flair) (4.11.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (23.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=2.2.3->flair) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=2.2.3->flair) (4.37.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=2.2.3->flair) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=2.2.3->flair) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn>=1.0.2->flair) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn>=1.0.2->flair) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn>=1.0.2->flair) (3.1.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (1.13.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.33.0)\n",
      "Collecting numpy (from stanza)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (5.9.2)\n",
      "Requirement already satisfied: click>=8.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (1.5.4)\n",
      "Requirement already satisfied: rich>=12.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (13.3.5)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.13.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (0.1.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.3.2.post1)\n",
      "Requirement already satisfied: sortedcontainers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair) (2.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.1.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch>=1.13.0->stanza) (1.3.0)\n",
      "Collecting udapi>=0.5.0 (from udtools>=0.2.4->stanza)\n",
      "  Downloading udapi-0.5.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: colorama in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from udapi>=0.5.0->udtools>=0.2.4->stanza) (0.4.6)\n",
      "Requirement already satisfied: termcolor in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from udapi>=0.5.0->udtools>=0.2.4->stanza) (2.4.0)\n",
      "Downloading spacy_stanza-1.0.4-py3-none-any.whl (9.7 kB)\n",
      "Downloading stanza-1.6.1-py3-none-any.whl (881 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.2/881.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flair-0.15.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bioc-2.1-py3-none-any.whl (33 kB)\n",
      "Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Downloading boto3-1.42.59-py3-none-any.whl (140 kB)\n",
      "Downloading botocore-1.42.59-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Downloading gdown-5.2.1-py3-none-any.whl (18 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "Downloading mpld3-0.5.12-py3-none-any.whl (203 kB)\n",
      "Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Downloading transformer_smaller_training_vocab-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading intervaltree-3.2.1-py2.py3-none-any.whl (25 kB)\n",
      "Building wheels for collected packages: langdetect, pptree, sqlitedict, wikipedia-api, docopt\n",
      "\u001b[33m  DEPRECATION: Building 'langdetect' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'langdetect'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=f5b210475492e0f330cf6e2b4be58642d23bbc556dd86c32e6c811a65806f1e7\n",
      "  Stored in directory: /Users/marvinwong/Library/Caches/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "\u001b[33m  DEPRECATION: Building 'pptree' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pptree'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for pptree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=889cf41f394972b87b76a237328aff3811f2f7d9acb300585adc246b03342b10\n",
      "  Stored in directory: /Users/marvinwong/Library/Caches/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
      "\u001b[33m  DEPRECATION: Building 'sqlitedict' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sqlitedict'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=421c2d2afde46d6f7d58d186fb826aa35b2d52257f47ee80c7353fd4e332e046\n",
      "  Stored in directory: /Users/marvinwong/Library/Caches/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
      "\u001b[33m  DEPRECATION: Building 'wikipedia-api' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'wikipedia-api'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for wikipedia-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia-api: filename=Wikipedia_API-0.9.0-py3-none-any.whl size=15423 sha256=df8e5318156a1940fe4578a9d80bf0b040af9101958a3972fbf0ca2c5057dcbf\n",
      "  Stored in directory: /Users/marvinwong/Library/Caches/pip/wheels/78/d8/ac/fe59f5cb634e5fb0b4bcd7938768e98b6b6c41edf430774197\n",
      "\u001b[33m  DEPRECATION: Building 'docopt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'docopt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=3b1593794ddcc0df9741c2b6f5d05b350dd988624d384be32f34c14889247e3a\n",
      "  Stored in directory: /Users/marvinwong/Library/Caches/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built langdetect pptree sqlitedict wikipedia-api docopt\n",
      "Installing collected packages: sqlitedict, pptree, docopt, segtok, numpy, more-itertools, langdetect, jsonlines, jmespath, intervaltree, ftfy, emoji, conllu, wikipedia-api, botocore, bioc, stanza, s3transfer, pytorch-revgrad, gdown, mpld3, boto3, transformer-smaller-training-vocab, spacy-stanza, flair\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/25\u001b[0m [flair]m24/25\u001b[0m [flair]]e]ree]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "giotto-tda 0.6.2 requires scikit-learn==1.3.2, but you have scikit-learn 1.7.2 which is incompatible.\n",
      "presidio-evaluator 0.2.5 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bioc-2.1 boto3-1.42.59 botocore-1.42.59 conllu-4.5.3 docopt-0.6.2 emoji-2.15.0 flair-0.15.1 ftfy-6.3.1 gdown-5.2.1 intervaltree-3.2.1 jmespath-1.1.0 jsonlines-4.0.0 langdetect-1.0.9 more-itertools-10.8.0 mpld3-0.5.12 numpy-1.26.4 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.16.0 segtok-1.5.11 spacy-stanza-1.0.4 sqlitedict-2.1.0 stanza-1.6.1 transformer-smaller-training-vocab-0.4.2 wikipedia-api-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stanza spacy-stanza flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40565999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdfc5bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting presidio-evaluator\n",
      "  Downloading presidio_evaluator-0.2.5-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting faker (from presidio-evaluator)\n",
      "  Downloading faker-40.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting numpy<3.0.0,>=2.0.0 (from presidio-evaluator)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-evaluator) (2.2.2)\n",
      "Collecting plotly<6.0.0,>=5.24.0 (from presidio-evaluator)\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting presidio-analyzer<3.0.0,>=2.2.351 (from presidio-evaluator)\n",
      "  Downloading presidio_analyzer-2.2.361-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting presidio-anonymizer<3.0.0,>=2.2.351 (from presidio-evaluator)\n",
      "  Downloading presidio_anonymizer-2.2.361-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-evaluator) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.25 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-evaluator) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-evaluator) (1.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.60.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-evaluator) (4.66.5)\n",
      "Collecting xmltodict<0.13.0,>=0.12.0 (from presidio-evaluator)\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.4->presidio-evaluator) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.4->presidio-evaluator) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.4->presidio-evaluator) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from plotly<6.0.0,>=5.24.0->presidio-evaluator) (8.2.2)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from plotly<6.0.0,>=5.24.0->presidio-evaluator) (24.1)\n",
      "Collecting phonenumbers<10.0.0,>=8.12 (from presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading phonenumbers-9.0.25-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pydantic<3.0.0,>=2.0.0 (from presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (6.0.1)\n",
      "Requirement already satisfied: regex in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (2023.10.3)\n",
      "Collecting spacy!=3.7.0,>=3.4.4 (from presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading spacy-3.8.11-cp310-cp310-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting tldextract (from presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading tldextract-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: cryptography>=46.0.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from presidio-anonymizer<3.0.0,>=2.2.351->presidio-evaluator) (46.0.5)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.0->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.0.0->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (4.14.1)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.0.0->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0,>=2.25->presidio-evaluator) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0,>=2.25->presidio-evaluator) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0,>=2.25->presidio-evaluator) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0,>=2.25->presidio-evaluator) (2025.8.3)\n",
      "INFO: pip is looking at multiple versions of scikit-learn to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scikit-learn<2.0.0,>=1.3.2 (from presidio-evaluator)\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.3.2->presidio-evaluator) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.3.2->presidio-evaluator) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.3.2->presidio-evaluator) (3.1.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cryptography>=46.0.4->presidio-anonymizer<3.0.0,>=2.2.351->presidio-evaluator) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cffi>=2.0.0->cryptography>=46.0.4->presidio-anonymizer<3.0.0,>=2.2.351->presidio-evaluator) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->presidio-evaluator) (1.16.0)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy>=1.8.0 (from scikit-learn<2.0.0,>=1.3.2->presidio-evaluator)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading murmurhash-1.0.15-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading cymem-2.0.13-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading preshed-3.0.12-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.5 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading thinc-8.3.10-cp310-cp310-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading srsly-2.5.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading typer_slim-0.24.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (63.2.0)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading blis-1.3.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting typer>=0.24.0 (from typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading typer-0.24.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading smart_open-7.5.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (1.16.0)\n",
      "Collecting click>=8.2.1 (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=12.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (13.3.5)\n",
      "Collecting annotated-doc>=0.0.2 (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (2.13.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->spacy!=3.7.0,>=3.4.4->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (2.1.1)\n",
      "Collecting requests-file>=1.4 (from tldextract->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator)\n",
      "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tldextract->presidio-analyzer<3.0.0,>=2.2.351->presidio-evaluator) (3.13.1)\n",
      "Downloading presidio_evaluator-0.2.5-py3-none-any.whl (658 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m658.4/658.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading presidio_analyzer-2.2.361-py3-none-any.whl (183 kB)\n",
      "Downloading phonenumbers-9.0.25-py2.py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading presidio_anonymizer-2.2.361-py3-none-any.whl (36 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp310-cp310-macosx_12_0_arm64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Downloading spacy-3.8.11-cp310-cp310-macosx_11_0_arm64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.13-cp310-cp310-macosx_11_0_arm64.whl (43 kB)\n",
      "Downloading murmurhash-1.0.15-cp310-cp310-macosx_11_0_arm64.whl (27 kB)\n",
      "Downloading preshed-3.0.12-cp310-cp310-macosx_11_0_arm64.whl (124 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.2-cp310-cp310-macosx_11_0_arm64.whl (653 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.4/653.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.10-cp310-cp310-macosx_11_0_arm64.whl (772 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.3/772.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.3-cp310-cp310-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading typer_slim-0.24.0-py3-none-any.whl (3.4 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading smart_open-7.5.1-py3-none-any.whl (64 kB)\n",
      "Downloading typer-0.24.1-py3-none-any.whl (56 kB)\n",
      "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading faker-40.5.1-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tldextract-5.3.1-py3-none-any.whl (105 kB)\n",
      "Downloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
      "Installing collected packages: xmltodict, wasabi, typing-inspection, spacy-loggers, spacy-legacy, smart-open, shellingham, pydantic-core, plotly, phonenumbers, numpy, murmurhash, faker, cymem, cloudpathlib, click, catalogue, annotated-types, annotated-doc, srsly, scipy, requests-file, pydantic, preshed, blis, typer, tldextract, scikit-learn, presidio-anonymizer, confection, typer-slim, thinc, weasel, spacy, presidio-analyzer, presidio-evaluator\n",
      "\u001b[2K  Attempting uninstall: plotly\n",
      "\u001b[2K    Found existing installation: plotly 5.14.1\n",
      "\u001b[2K    Uninstalling plotly-5.14.1:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/36\u001b[0m [plotly]\n",
      "\u001b[2K      Successfully uninstalled plotly-5.14.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/36\u001b[0m [plotly]\n",
      "\u001b[2K  Attempting uninstall: numpy[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/36\u001b[0m [phonenumbers]\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/36\u001b[0m [phonenumbers]\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/36\u001b[0m [phonenumbers]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/36\u001b[0m [phonenumbers]\n",
      "\u001b[2K  Attempting uninstall: clickm╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/36\u001b[0m [faker]rs]\n",
      "\u001b[2K    Found existing installation: click 8.1.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/36\u001b[0m [faker]\n",
      "\u001b[2K    Uninstalling click-8.1.3:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/36\u001b[0m [faker]\n",
      "\u001b[2K      Successfully uninstalled click-8.1.3━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/36\u001b[0m [faker]\n",
      "\u001b[2K  Attempting uninstall: scipy[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/36\u001b[0m [click]\n",
      "\u001b[2K    Found existing installation: scipy 1.10.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/36\u001b[0m [click]\n",
      "\u001b[2K    Uninstalling scipy-1.10.0:\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/36\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.10.00m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/36\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: scikit-learn\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [pydantic]\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.3.2━━━━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling scikit-learn-1.3.2:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [pydantic]\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.3.2━━━━━━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [pydantic]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/36\u001b[0m [presidio-evaluator]pacy]slim]n]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "accelerate 0.33.0 requires numpy<2.0.0,>=1.17, but you have numpy 2.2.6 which is incompatible.\n",
      "derivative 0.6.2 requires numpy<2.0.0,>=1.18.3, but you have numpy 2.2.6 which is incompatible.\n",
      "giotto-tda 0.6.2 requires scikit-learn==1.3.2, but you have scikit-learn 1.7.2 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-doc-0.0.4 annotated-types-0.7.0 blis-1.3.3 catalogue-2.0.10 click-8.3.1 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 faker-40.5.1 murmurhash-1.0.15 numpy-2.2.6 phonenumbers-9.0.25 plotly-5.24.1 preshed-3.0.12 presidio-analyzer-2.2.361 presidio-anonymizer-2.2.361 presidio-evaluator-0.2.5 pydantic-2.12.5 pydantic-core-2.41.5 requests-file-3.0.1 scikit-learn-1.7.2 scipy-1.15.3 shellingham-1.5.4 smart-open-7.5.1 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 thinc-8.3.10 tldextract-5.3.1 typer-0.24.1 typer-slim-0.24.0 typing-inspection-0.4.2 wasabi-1.1.3 weasel-0.4.3 xmltodict-0.12.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install presidio-evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851157d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 400.7/400.7 MB 30.2 MB/s  0:00:12\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: pip3.10 install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "# Import Presidio Evaluator components\n",
    "from presidio_evaluator import Span\n",
    "from presidio_evaluator.evaluation import SpanEvaluator\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "# Loading the vanilla Analyzer Engine, with the default NER model.\n",
    "analyzer_engine = AnalyzerEngine(default_score_threshold=0.4)\n",
    "\n",
    "# 1. Load the secrets from the .env file into your computer's memory\n",
    "load_dotenv()\n",
    "\n",
    "# 2. Grab them using their variable names (NOT the actual string!)\n",
    "endpoint = os.environ.get(\"AZURE_LANGUAGE_ENDPOINT\")\n",
    "key = os.environ.get(\"AZURE_LANGUAGE_KEY\")\n",
    "\n",
    "# 3. Add a quick safety check so it doesn't crash cryptically again\n",
    "if not key or not endpoint:\n",
    "    raise ValueError(\"Missing Azure keys! Check your .env file.\")\n",
    "\n",
    "# 4. Connect to Azure\n",
    "client = TextAnalyticsClient(endpoint, AzureKeyCredential(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1835cf4f",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd3eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_PII_MAPPING = {\n",
    "    'ADDRESS': 'Address',\n",
    "    'AGE': 'Age',\n",
    "    'BIRTHDAY': 'DateTime',\n",
    "    'CITY': 'Location',               # Azure often categorizes cities as Location or Address\n",
    "    'CREDIT_CARD': 'CreditCardNumber',\n",
    "    'CREDIT_CARD_NUMBER': 'CreditCardNumber',\n",
    "    'DATE': 'DateTime',\n",
    "    'DATE_OF_BIRTH': 'DateTime',\n",
    "    'DATE_TIME': 'DateTime',\n",
    "    'DOB': 'DateTime',\n",
    "    'DOMAIN': 'URL',\n",
    "    'DOMAIN_NAME': 'URL',\n",
    "    'EMAIL': 'Email',\n",
    "    'EMAIL_ADDRESS': 'Email',\n",
    "    'FACILITY': 'Organization',       # Facilities/Hospitals roll into Organization\n",
    "    'FIRST_NAME': 'Person',\n",
    "    'GPE': 'Location',\n",
    "    'HCW': 'Person',                  # Health Care Worker\n",
    "    'HOSP': 'Organization',\n",
    "    'HOSPITAL': 'Organization',\n",
    "    'IBAN': 'InternationalBankingAccountNumber',\n",
    "    'IBAN_CODE': 'InternationalBankingAccountNumber',\n",
    "    'ID': 'NationalIdentityNumber',   # Generic fallback for IDs in Azure\n",
    "    'IP_ADDRESS': 'IPAddress',\n",
    "    'LAST_NAME': 'Person',\n",
    "    'LOC': 'Location',\n",
    "    'LOCATION': 'Location',\n",
    "    'NAME': 'Person',\n",
    "    'NATIONALITY': 'O',               # Azure PII doesn't strictly flag Nationality/NRP as PII\n",
    "    'NORP': 'O',                      # (Nationalities, Religious, Political groups)\n",
    "    'NRP': 'O',\n",
    "    'O': 'O',\n",
    "    'ORG': 'Organization',\n",
    "    'ORGANIZATION': 'Organization',\n",
    "    'PATIENT': 'Person',\n",
    "    'PATORG': 'Organization',\n",
    "    'PER': 'Person',\n",
    "    'PERSON': 'Person',\n",
    "    'PHONE': 'PhoneNumber',\n",
    "    'PHONE_NUMBER': 'PhoneNumber',\n",
    "    'PREFIX': 'PersonType',           # Azure uses PersonType for Mr., Mrs., Dr., etc.\n",
    "    'SSN': 'USSocialSecurityNumber',\n",
    "    'STAFF': 'Person',\n",
    "    'STREET_ADDRESS': 'Address',\n",
    "    'TIME': 'DateTime',\n",
    "    'TITLE': 'PersonType',            # Azure uses PersonType for job titles/roles\n",
    "    'URL': 'URL',\n",
    "    'US_DRIVER_LICENSE': 'USDriversLicenseNumber',\n",
    "    'US_SSN': 'USSocialSecurityNumber',\n",
    "    'VENDOR': 'Organization',\n",
    "    'ZIP': 'Address',                 # Azure groups zip codes under the larger Address entity\n",
    "    'ZIP_CODE': 'Address'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ca9db",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d131836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "    \"\"\"Loads the JSON dataset from the specified file path.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "046dcf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the data from your specific JSON file\n",
    "json_file_path = \"../data/synth_dataset_v2.json\"\n",
    "my_dataset = load_dataset(json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3983efd8",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bff77bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1500 documents for Azure Evaluation...\n",
      "\n",
      "Processed 5 / 1500 documents...\n",
      "Processed 10 / 1500 documents...\n",
      "Processed 15 / 1500 documents...\n",
      "Processed 20 / 1500 documents...\n",
      "Processed 25 / 1500 documents...\n",
      "Processed 30 / 1500 documents...\n",
      "Processed 35 / 1500 documents...\n",
      "Processed 40 / 1500 documents...\n",
      "Processed 45 / 1500 documents...\n",
      "Processed 50 / 1500 documents...\n",
      "Processed 55 / 1500 documents...\n",
      "Processed 60 / 1500 documents...\n",
      "Processed 65 / 1500 documents...\n",
      "Processed 70 / 1500 documents...\n",
      "Processed 75 / 1500 documents...\n",
      "Processed 80 / 1500 documents...\n",
      "Processed 85 / 1500 documents...\n",
      "Processed 90 / 1500 documents...\n",
      "Processed 95 / 1500 documents...\n",
      "Processed 100 / 1500 documents...\n",
      "Processed 105 / 1500 documents...\n",
      "Processed 110 / 1500 documents...\n",
      "Processed 115 / 1500 documents...\n",
      "Processed 120 / 1500 documents...\n",
      "Processed 125 / 1500 documents...\n",
      "Processed 130 / 1500 documents...\n",
      "Processed 135 / 1500 documents...\n",
      "Processed 140 / 1500 documents...\n",
      "Processed 145 / 1500 documents...\n",
      "Processed 150 / 1500 documents...\n",
      "Processed 155 / 1500 documents...\n",
      "Processed 160 / 1500 documents...\n",
      "Processed 165 / 1500 documents...\n",
      "Processed 170 / 1500 documents...\n",
      "Processed 175 / 1500 documents...\n",
      "Processed 180 / 1500 documents...\n",
      "Processed 185 / 1500 documents...\n",
      "Processed 190 / 1500 documents...\n",
      "Processed 195 / 1500 documents...\n",
      "Processed 200 / 1500 documents...\n",
      "Processed 205 / 1500 documents...\n",
      "Processed 210 / 1500 documents...\n",
      "Processed 215 / 1500 documents...\n",
      "Processed 220 / 1500 documents...\n",
      "Processed 225 / 1500 documents...\n",
      "Processed 230 / 1500 documents...\n",
      "Processed 235 / 1500 documents...\n",
      "Processed 240 / 1500 documents...\n",
      "Processed 245 / 1500 documents...\n",
      "Processed 250 / 1500 documents...\n",
      "Processed 255 / 1500 documents...\n",
      "Processed 260 / 1500 documents...\n",
      "Processed 265 / 1500 documents...\n",
      "Processed 270 / 1500 documents...\n",
      "Processed 275 / 1500 documents...\n",
      "Processed 280 / 1500 documents...\n",
      "Processed 285 / 1500 documents...\n",
      "Processed 290 / 1500 documents...\n",
      "Processed 295 / 1500 documents...\n",
      "Processed 300 / 1500 documents...\n",
      "Processed 305 / 1500 documents...\n",
      "Processed 310 / 1500 documents...\n",
      "Processed 315 / 1500 documents...\n",
      "Processed 320 / 1500 documents...\n",
      "Processed 325 / 1500 documents...\n",
      "Processed 330 / 1500 documents...\n",
      "Processed 335 / 1500 documents...\n",
      "Processed 340 / 1500 documents...\n",
      "Processed 345 / 1500 documents...\n",
      "Processed 350 / 1500 documents...\n",
      "Processed 355 / 1500 documents...\n",
      "Processed 360 / 1500 documents...\n",
      "Processed 365 / 1500 documents...\n",
      "Processed 370 / 1500 documents...\n",
      "Processed 375 / 1500 documents...\n",
      "Processed 380 / 1500 documents...\n",
      "Processed 385 / 1500 documents...\n",
      "Processed 390 / 1500 documents...\n",
      "Processed 395 / 1500 documents...\n",
      "Processed 400 / 1500 documents...\n",
      "Processed 405 / 1500 documents...\n",
      "Processed 410 / 1500 documents...\n",
      "Processed 415 / 1500 documents...\n",
      "Processed 420 / 1500 documents...\n",
      "Processed 425 / 1500 documents...\n",
      "Processed 430 / 1500 documents...\n",
      "Processed 435 / 1500 documents...\n",
      "Processed 440 / 1500 documents...\n",
      "Processed 445 / 1500 documents...\n",
      "Processed 450 / 1500 documents...\n",
      "Processed 455 / 1500 documents...\n",
      "Processed 460 / 1500 documents...\n",
      "Processed 465 / 1500 documents...\n",
      "Processed 470 / 1500 documents...\n",
      "Processed 475 / 1500 documents...\n",
      "Processed 480 / 1500 documents...\n",
      "Processed 485 / 1500 documents...\n",
      "Processed 490 / 1500 documents...\n",
      "Processed 495 / 1500 documents...\n",
      "Processed 500 / 1500 documents...\n",
      "Processed 505 / 1500 documents...\n",
      "Processed 510 / 1500 documents...\n",
      "Processed 515 / 1500 documents...\n",
      "Processed 520 / 1500 documents...\n",
      "Processed 525 / 1500 documents...\n",
      "Processed 530 / 1500 documents...\n",
      "Processed 535 / 1500 documents...\n",
      "Processed 540 / 1500 documents...\n",
      "Processed 545 / 1500 documents...\n",
      "Processed 550 / 1500 documents...\n",
      "Processed 555 / 1500 documents...\n",
      "Processed 560 / 1500 documents...\n",
      "Processed 565 / 1500 documents...\n",
      "Processed 570 / 1500 documents...\n",
      "Processed 575 / 1500 documents...\n",
      "Processed 580 / 1500 documents...\n",
      "Processed 585 / 1500 documents...\n",
      "Processed 590 / 1500 documents...\n",
      "Processed 595 / 1500 documents...\n",
      "Processed 600 / 1500 documents...\n",
      "Processed 605 / 1500 documents...\n",
      "Processed 610 / 1500 documents...\n",
      "Processed 615 / 1500 documents...\n",
      "Processed 620 / 1500 documents...\n",
      "Processed 625 / 1500 documents...\n",
      "Processed 630 / 1500 documents...\n",
      "Processed 635 / 1500 documents...\n",
      "Processed 640 / 1500 documents...\n",
      "Processed 645 / 1500 documents...\n",
      "Processed 650 / 1500 documents...\n",
      "Processed 655 / 1500 documents...\n",
      "Processed 660 / 1500 documents...\n",
      "Processed 665 / 1500 documents...\n",
      "Processed 670 / 1500 documents...\n",
      "Processed 675 / 1500 documents...\n",
      "Processed 680 / 1500 documents...\n",
      "Processed 685 / 1500 documents...\n",
      "Processed 690 / 1500 documents...\n",
      "Processed 695 / 1500 documents...\n",
      "Processed 700 / 1500 documents...\n",
      "Processed 705 / 1500 documents...\n",
      "Processed 710 / 1500 documents...\n",
      "Processed 715 / 1500 documents...\n",
      "Processed 720 / 1500 documents...\n",
      "Processed 725 / 1500 documents...\n",
      "Processed 730 / 1500 documents...\n",
      "Processed 735 / 1500 documents...\n",
      "Processed 740 / 1500 documents...\n",
      "Processed 745 / 1500 documents...\n",
      "Processed 750 / 1500 documents...\n",
      "Processed 755 / 1500 documents...\n",
      "Processed 760 / 1500 documents...\n",
      "Processed 765 / 1500 documents...\n",
      "Processed 770 / 1500 documents...\n",
      "Processed 775 / 1500 documents...\n",
      "Processed 780 / 1500 documents...\n",
      "Processed 785 / 1500 documents...\n",
      "Processed 790 / 1500 documents...\n",
      "Processed 795 / 1500 documents...\n",
      "Processed 800 / 1500 documents...\n",
      "Processed 805 / 1500 documents...\n",
      "Processed 810 / 1500 documents...\n",
      "Processed 815 / 1500 documents...\n",
      "Processed 820 / 1500 documents...\n",
      "Processed 825 / 1500 documents...\n",
      "Processed 830 / 1500 documents...\n",
      "Processed 835 / 1500 documents...\n",
      "Processed 840 / 1500 documents...\n",
      "Processed 845 / 1500 documents...\n",
      "Processed 850 / 1500 documents...\n",
      "Processed 855 / 1500 documents...\n",
      "Processed 860 / 1500 documents...\n",
      "Processed 865 / 1500 documents...\n",
      "Processed 870 / 1500 documents...\n",
      "Processed 875 / 1500 documents...\n",
      "Processed 880 / 1500 documents...\n",
      "Processed 885 / 1500 documents...\n",
      "Processed 890 / 1500 documents...\n",
      "Processed 895 / 1500 documents...\n",
      "Processed 900 / 1500 documents...\n",
      "Processed 905 / 1500 documents...\n",
      "Processed 910 / 1500 documents...\n",
      "Processed 915 / 1500 documents...\n",
      "Processed 920 / 1500 documents...\n",
      "Processed 925 / 1500 documents...\n",
      "Processed 930 / 1500 documents...\n",
      "Processed 935 / 1500 documents...\n",
      "Processed 940 / 1500 documents...\n",
      "Processed 945 / 1500 documents...\n",
      "Processed 950 / 1500 documents...\n",
      "Processed 955 / 1500 documents...\n",
      "Processed 960 / 1500 documents...\n",
      "Processed 965 / 1500 documents...\n",
      "Processed 970 / 1500 documents...\n",
      "Processed 975 / 1500 documents...\n",
      "Processed 980 / 1500 documents...\n",
      "Processed 985 / 1500 documents...\n",
      "Processed 990 / 1500 documents...\n",
      "Processed 995 / 1500 documents...\n",
      "Processed 1000 / 1500 documents...\n",
      "Processed 1005 / 1500 documents...\n",
      "Processed 1010 / 1500 documents...\n",
      "Processed 1015 / 1500 documents...\n",
      "Processed 1020 / 1500 documents...\n",
      "Processed 1025 / 1500 documents...\n",
      "Processed 1030 / 1500 documents...\n",
      "Processed 1035 / 1500 documents...\n",
      "Processed 1040 / 1500 documents...\n",
      "Processed 1045 / 1500 documents...\n",
      "Processed 1050 / 1500 documents...\n",
      "Processed 1055 / 1500 documents...\n",
      "Processed 1060 / 1500 documents...\n",
      "Processed 1065 / 1500 documents...\n",
      "Processed 1070 / 1500 documents...\n",
      "Processed 1075 / 1500 documents...\n",
      "Processed 1080 / 1500 documents...\n",
      "Processed 1085 / 1500 documents...\n",
      "Processed 1090 / 1500 documents...\n",
      "Processed 1095 / 1500 documents...\n",
      "Processed 1100 / 1500 documents...\n",
      "Processed 1105 / 1500 documents...\n",
      "Processed 1110 / 1500 documents...\n",
      "Processed 1115 / 1500 documents...\n",
      "Processed 1120 / 1500 documents...\n",
      "Processed 1125 / 1500 documents...\n",
      "Processed 1130 / 1500 documents...\n",
      "Processed 1135 / 1500 documents...\n",
      "Processed 1140 / 1500 documents...\n",
      "Processed 1145 / 1500 documents...\n",
      "Processed 1150 / 1500 documents...\n",
      "Processed 1155 / 1500 documents...\n",
      "Processed 1160 / 1500 documents...\n",
      "Processed 1165 / 1500 documents...\n",
      "Processed 1170 / 1500 documents...\n",
      "Processed 1175 / 1500 documents...\n",
      "Processed 1180 / 1500 documents...\n",
      "Processed 1185 / 1500 documents...\n",
      "Processed 1190 / 1500 documents...\n",
      "Processed 1195 / 1500 documents...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1200 / 1500 documents...\n",
      "Processed 1205 / 1500 documents...\n",
      "Processed 1210 / 1500 documents...\n",
      "Processed 1215 / 1500 documents...\n",
      "Processed 1220 / 1500 documents...\n",
      "Processed 1225 / 1500 documents...\n",
      "Processed 1230 / 1500 documents...\n",
      "Processed 1235 / 1500 documents...\n",
      "Processed 1240 / 1500 documents...\n",
      "Processed 1245 / 1500 documents...\n",
      "Processed 1250 / 1500 documents...\n",
      "Processed 1255 / 1500 documents...\n",
      "Processed 1260 / 1500 documents...\n",
      "Processed 1265 / 1500 documents...\n",
      "Processed 1270 / 1500 documents...\n",
      "Processed 1275 / 1500 documents...\n",
      "Processed 1280 / 1500 documents...\n",
      "Processed 1285 / 1500 documents...\n",
      "Processed 1290 / 1500 documents...\n",
      "Processed 1295 / 1500 documents...\n",
      "Processed 1300 / 1500 documents...\n",
      "Processed 1305 / 1500 documents...\n",
      "Processed 1310 / 1500 documents...\n",
      "Processed 1315 / 1500 documents...\n",
      "Processed 1320 / 1500 documents...\n",
      "Processed 1325 / 1500 documents...\n",
      "Processed 1330 / 1500 documents...\n",
      "Processed 1335 / 1500 documents...\n",
      "Processed 1340 / 1500 documents...\n",
      "Processed 1345 / 1500 documents...\n",
      "Processed 1350 / 1500 documents...\n",
      "Processed 1355 / 1500 documents...\n",
      "Processed 1360 / 1500 documents...\n",
      "Processed 1365 / 1500 documents...\n",
      "Processed 1370 / 1500 documents...\n",
      "Processed 1375 / 1500 documents...\n",
      "Processed 1380 / 1500 documents...\n",
      "Processed 1385 / 1500 documents...\n",
      "Processed 1390 / 1500 documents...\n",
      "Processed 1395 / 1500 documents...\n",
      "Processed 1400 / 1500 documents...\n",
      "Processed 1405 / 1500 documents...\n",
      "Processed 1410 / 1500 documents...\n",
      "Processed 1415 / 1500 documents...\n",
      "Processed 1420 / 1500 documents...\n",
      "Processed 1425 / 1500 documents...\n",
      "Processed 1430 / 1500 documents...\n",
      "Processed 1435 / 1500 documents...\n",
      "Processed 1440 / 1500 documents...\n",
      "Processed 1445 / 1500 documents...\n",
      "Processed 1450 / 1500 documents...\n",
      "Processed 1455 / 1500 documents...\n",
      "Processed 1460 / 1500 documents...\n",
      "Processed 1465 / 1500 documents...\n",
      "Processed 1470 / 1500 documents...\n",
      "Processed 1475 / 1500 documents...\n",
      "Processed 1480 / 1500 documents...\n",
      "Processed 1485 / 1500 documents...\n",
      "Processed 1490 / 1500 documents...\n",
      "Processed 1495 / 1500 documents...\n",
      "Processed 1500 / 1500 documents...\n",
      "\n",
      "Calculating metrics using Presidio 1:1 Greedy Matching...\n",
      "\n",
      "==================================================\n",
      "      AZURE PII EVALUATION RESULTS      \n",
      "==================================================\n",
      "Total Ground Truth Entities: 2808\n",
      "Total Predicted Entities:    2698\n",
      "--------------------------------------------------\n",
      " STRICT MATCHING (Exact Character Bounds)\n",
      "   Precision: 0.5615\n",
      "   Recall:    0.5395\n",
      "   F1-Score:  0.5503\n",
      "--------------------------------------------------\n",
      " SOFT MATCHING (1:1 Greedy Overlap)\n",
      "   Precision: 0.7031\n",
      "   Recall:    0.6756\n",
      "   F1-Score:  0.6891\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def run_evaluation_presidio_replica(dataset):\n",
    "    all_ground_truth_sets = []\n",
    "    all_predicted_sets = []\n",
    "    \n",
    "    batch_size = 5\n",
    "    total_docs = len(dataset)\n",
    "    print(f\"Processing {total_docs} documents for Azure Evaluation...\\n\")\n",
    "    \n",
    "    # --- 1 & 2. FETCH AND FORMAT DATA ---\n",
    "    for i in range(0, total_docs, batch_size):\n",
    "        batch = dataset[i:i + batch_size]\n",
    "        texts = [doc[\"full_text\"] for doc in batch]\n",
    "        \n",
    "        # Call Azure API\n",
    "        response = client.recognize_pii_entities(texts, language=\"en\")\n",
    "        \n",
    "        for doc_idx, result in enumerate(response):\n",
    "            if result.is_error:\n",
    "                all_ground_truth_sets.append(set())\n",
    "                all_predicted_sets.append(set())\n",
    "                continue\n",
    "            \n",
    "            # Ground Truth Tuples: (Type, Start, End)\n",
    "            doc_gt = set()\n",
    "            for span in batch[doc_idx][\"spans\"]:\n",
    "                mapped_type = AZURE_PII_MAPPING.get(span[\"entity_type\"], span[\"entity_type\"])\n",
    "                if mapped_type != 'O': \n",
    "                    doc_gt.add((mapped_type, span[\"start_position\"], span[\"end_position\"]))\n",
    "            all_ground_truth_sets.append(doc_gt)\n",
    "            \n",
    "            # Predicted Tuples: (Type, Start, End)\n",
    "            doc_pred = set()\n",
    "            for entity in result.entities:\n",
    "                doc_pred.add((entity.category, entity.offset, entity.offset + entity.length))\n",
    "            all_predicted_sets.append(doc_pred)\n",
    "            \n",
    "        print(f\"Processed {min(i + batch_size, total_docs)} / {total_docs} documents...\")\n",
    "\n",
    "    # --- 3. CALCULATE STRICT & SOFT METRICS (Presidio Replica) ---\n",
    "    print(\"\\nCalculating metrics using Presidio 1:1 Greedy Matching...\")\n",
    "    \n",
    "    total_gt = 0\n",
    "    total_pred = 0\n",
    "    \n",
    "    strict_matched = 0\n",
    "    soft_matched = 0\n",
    "    \n",
    "    for gt_set, pred_set in zip(all_ground_truth_sets, all_predicted_sets):\n",
    "        total_gt += len(gt_set)\n",
    "        total_pred += len(pred_set)\n",
    "        \n",
    "        # STRICT MATCHES: Exact set intersection\n",
    "        strict_matched += len(gt_set.intersection(pred_set))\n",
    "        \n",
    "        # SOFT MATCHES: Greedy 1:1 Bipartite Matching\n",
    "        gt_list = list(gt_set)\n",
    "        pred_list = list(pred_set)\n",
    "        overlaps = []\n",
    "        \n",
    "        # Step A: Find all overlapping pairs and calculate the size of the overlap\n",
    "        for gt_idx, gt in enumerate(gt_list):\n",
    "            gt_type, gt_start, gt_end = gt\n",
    "            for pred_idx, pred in enumerate(pred_list):\n",
    "                pred_type, pred_start, pred_end = pred\n",
    "                \n",
    "                if gt_type == pred_type:\n",
    "                    overlap_length = min(gt_end, pred_end) - max(gt_start, pred_start)\n",
    "                    if overlap_length > 0:\n",
    "                        overlaps.append((overlap_length, gt_idx, pred_idx))\n",
    "                        \n",
    "        # Step B: Sort by largest overlap first\n",
    "        overlaps.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # Step C: Assign matches greedily (1-to-1)\n",
    "        claimed_gts = set()\n",
    "        claimed_preds = set()\n",
    "        \n",
    "        for overlap_length, gt_idx, pred_idx in overlaps:\n",
    "            if gt_idx not in claimed_gts and pred_idx not in claimed_preds:\n",
    "                claimed_gts.add(gt_idx)\n",
    "                claimed_preds.add(pred_idx)\n",
    "                soft_matched += 1\n",
    "\n",
    "    # --- 4. FINALIZE MATH ---\n",
    "    def calc_f1(precision, recall):\n",
    "        return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    # Strict Math\n",
    "    strict_precision = strict_matched / total_pred if total_pred > 0 else 0.0\n",
    "    strict_recall = strict_matched / total_gt if total_gt > 0 else 0.0\n",
    "    strict_f1 = calc_f1(strict_precision, strict_recall)\n",
    "\n",
    "    # Soft Math\n",
    "    soft_precision = soft_matched / total_pred if total_pred > 0 else 0.0\n",
    "    soft_recall = soft_matched / total_gt if total_gt > 0 else 0.0\n",
    "    soft_f1 = calc_f1(soft_precision, soft_recall)\n",
    "\n",
    "    # --- 5. PRINT RESULTS ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"      AZURE PII EVALUATION RESULTS      \")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total Ground Truth Entities: {total_gt}\")\n",
    "    print(f\"Total Predicted Entities:    {total_pred}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\" STRICT MATCHING (Exact Character Bounds)\")\n",
    "    print(f\"   Precision: {strict_precision:.4f}\")\n",
    "    print(f\"   Recall:    {strict_recall:.4f}\")\n",
    "    print(f\"   F1-Score:  {strict_f1:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\" SOFT MATCHING (1:1 Greedy Overlap)\")\n",
    "    print(f\"   Precision: {soft_precision:.4f}\")\n",
    "    print(f\"   Recall:    {soft_recall:.4f}\")\n",
    "    print(f\"   F1-Score:  {soft_f1:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "run_evaluation_presidio_replica(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1956ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
