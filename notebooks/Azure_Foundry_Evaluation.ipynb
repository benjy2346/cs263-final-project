{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f8bcf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-textanalytics\n",
      "  Using cached azure_ai_textanalytics-5.3.0-py3-none-any.whl.metadata (82 kB)\n",
      "Collecting azure-identity\n",
      "  Using cached azure_identity-1.25.2-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting azure-core<2.0.0,>=1.24.0 (from azure-ai-textanalytics)\n",
      "  Using cached azure_core-1.38.2-py3-none-any.whl.metadata (48 kB)\n",
      "Collecting azure-common~=1.1 (from azure-ai-textanalytics)\n",
      "  Using cached azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting isodate<1.0.0,>=0.6.1 (from azure-ai-textanalytics)\n",
      "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from azure-ai-textanalytics) (4.14.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.32.3)\n",
      "Collecting cryptography>=2.5 (from azure-identity)\n",
      "  Downloading cryptography-46.0.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting msal>=1.31.0 (from azure-identity)\n",
      "  Using cached msal-1.35.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity)\n",
      "  Using cached msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=2.5->azure-identity)\n",
      "  Downloading cffi-2.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity) (2.21)\n",
      "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal>=1.31.0->azure-identity)\n",
      "  Downloading pyjwt-2.11.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2025.8.3)\n",
      "Using cached azure_ai_textanalytics-5.3.0-py3-none-any.whl (298 kB)\n",
      "Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Using cached azure_core-1.38.2-py3-none-any.whl (217 kB)\n",
      "Using cached isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Using cached azure_identity-1.25.2-py3-none-any.whl (191 kB)\n",
      "Downloading cryptography-46.0.5-cp38-abi3-macosx_10_9_universal2.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cffi-2.0.0-cp310-cp310-macosx_11_0_arm64.whl (180 kB)\n",
      "Using cached msal-1.35.0-py3-none-any.whl (120 kB)\n",
      "Downloading pyjwt-2.11.0-py3-none-any.whl (28 kB)\n",
      "Using cached msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: azure-common, PyJWT, isodate, cffi, cryptography, azure-core, azure-ai-textanalytics, msal, msal-extensions, azure-identity\n",
      "\u001b[2K  Attempting uninstall: cffi\n",
      "\u001b[2K    Found existing installation: cffi 1.15.1\n",
      "\u001b[2K    Uninstalling cffi-1.15.1:\n",
      "\u001b[2K      Successfully uninstalled cffi-1.15.1━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [cffi]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [azure-identity]m [azure-identity]alytics]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyJWT-2.11.0 azure-ai-textanalytics-5.3.0 azure-common-1.1.28 azure-core-1.38.2 azure-identity-1.25.2 cffi-2.0.0 cryptography-46.0.5 isodate-0.7.2 msal-1.35.0 msal-extensions-1.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-ai-textanalytics azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "093e8c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1835cf4f",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dd3eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_PII_MAPPING = {\n",
    "    'ADDRESS': 'Address',\n",
    "    'AGE': 'Age',\n",
    "    'BIRTHDAY': 'DateTime',\n",
    "    'CITY': 'Location',               # Azure often categorizes cities as Location or Address\n",
    "    'CREDIT_CARD': 'CreditCardNumber',\n",
    "    'CREDIT_CARD_NUMBER': 'CreditCardNumber',\n",
    "    'DATE': 'DateTime',\n",
    "    'DATE_OF_BIRTH': 'DateTime',\n",
    "    'DATE_TIME': 'DateTime',\n",
    "    'DOB': 'DateTime',\n",
    "    'DOMAIN': 'URL',\n",
    "    'DOMAIN_NAME': 'URL',\n",
    "    'EMAIL': 'Email',\n",
    "    'EMAIL_ADDRESS': 'Email',\n",
    "    'FACILITY': 'Organization',       # Facilities/Hospitals roll into Organization\n",
    "    'FIRST_NAME': 'Person',\n",
    "    'GPE': 'Location',\n",
    "    'HCW': 'Person',                  # Health Care Worker\n",
    "    'HOSP': 'Organization',\n",
    "    'HOSPITAL': 'Organization',\n",
    "    'IBAN': 'InternationalBankingAccountNumber',\n",
    "    'IBAN_CODE': 'InternationalBankingAccountNumber',\n",
    "    'ID': 'NationalIdentityNumber',   # Generic fallback for IDs in Azure\n",
    "    'IP_ADDRESS': 'IPAddress',\n",
    "    'LAST_NAME': 'Person',\n",
    "    'LOC': 'Location',\n",
    "    'LOCATION': 'Location',\n",
    "    'NAME': 'Person',\n",
    "    'NATIONALITY': 'O',               # Azure PII doesn't strictly flag Nationality/NRP as PII\n",
    "    'NORP': 'O',                      # (Nationalities, Religious, Political groups)\n",
    "    'NRP': 'O',\n",
    "    'O': 'O',\n",
    "    'ORG': 'Organization',\n",
    "    'ORGANIZATION': 'Organization',\n",
    "    'PATIENT': 'Person',\n",
    "    'PATORG': 'Organization',\n",
    "    'PER': 'Person',\n",
    "    'PERSON': 'Person',\n",
    "    'PHONE': 'PhoneNumber',\n",
    "    'PHONE_NUMBER': 'PhoneNumber',\n",
    "    'PREFIX': 'PersonType',           # Azure uses PersonType for Mr., Mrs., Dr., etc.\n",
    "    'SSN': 'USSocialSecurityNumber',\n",
    "    'STAFF': 'Person',\n",
    "    'STREET_ADDRESS': 'Address',\n",
    "    'TIME': 'DateTime',\n",
    "    'TITLE': 'PersonType',            # Azure uses PersonType for job titles/roles\n",
    "    'URL': 'URL',\n",
    "    'US_DRIVER_LICENSE': 'USDriversLicenseNumber',\n",
    "    'US_SSN': 'USSocialSecurityNumber',\n",
    "    'VENDOR': 'Organization',\n",
    "    'ZIP': 'Address',                 # Azure groups zip codes under the larger Address entity\n",
    "    'ZIP_CODE': 'Address'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ca9db",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d131836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "    \"\"\"Loads the JSON dataset from the specified file path.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "046dcf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the data from your specific JSON file\n",
    "json_file_path = \"synth_dataset_v2.json\"\n",
    "my_dataset = load_dataset(json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3983efd8",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bff77bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EVALUATION RESULTS ---\n",
      "True Positives (Exact Matches): 1515\n",
      "False Positives (Hallucinations/Over-tagging): 1183\n",
      "False Negatives (Missed PII): 1348\n",
      "--------------------------\n",
      "Precision: 0.5615\n",
      "Recall:    0.5292\n",
      "F1-Score:  0.5449\n"
     ]
    }
   ],
   "source": [
    "def evaluate_pii_dataset(dataset):\n",
    "    # Metrics counters\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    # Process in batches of 5 (Azure's standard limit for this API call)\n",
    "    batch_size = 5\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        batch = dataset[i:i + batch_size]\n",
    "        texts = [doc[\"full_text\"] for doc in batch]\n",
    "        \n",
    "        # Call Azure API\n",
    "        response = client.recognize_pii_entities(texts, language=\"en\")\n",
    "        \n",
    "        for doc_idx, result in enumerate(response):\n",
    "            if result.is_error:\n",
    "                print(f\"Error in document: {result.error}\")\n",
    "                continue\n",
    "            \n",
    "            ground_truth_spans = batch[doc_idx][\"spans\"]\n",
    "            \n",
    "            # Extract predicted spans formatting them like your ground truth\n",
    "            predicted_spans = []\n",
    "            for entity in result.entities:\n",
    "                predicted_spans.append({\n",
    "                    \"entity_type\": entity.category,\n",
    "                    \"start_position\": entity.offset,\n",
    "                    \"end_position\": entity.offset + entity.length\n",
    "                })\n",
    "            \n",
    "            # --- EVALUATION LOGIC ---\n",
    "            # Create sets of tuples for easy comparison: (start, end, type)\n",
    "            gt_set = set()\n",
    "            for span in ground_truth_spans:\n",
    "                # Map your dataset's category to Azure's format for a fair comparison\n",
    "                mapped_type = AZURE_PII_MAPPING.get(span[\"entity_type\"], span[\"entity_type\"])\n",
    "                gt_set.add((span[\"start_position\"], span[\"end_position\"], mapped_type))\n",
    "                \n",
    "            pred_set = set()\n",
    "            for span in predicted_spans:\n",
    "                pred_set.add((span[\"start_position\"], span[\"end_position\"], span[\"entity_type\"]))\n",
    "\n",
    "            # Calculate intersections and differences\n",
    "            matched = gt_set.intersection(pred_set)\n",
    "            \n",
    "            # True Positives: Predicted perfectly matches Ground Truth (offset and type)\n",
    "            tp = len(matched)\n",
    "            # False Positives: Predicted by Azure, but not in Ground Truth\n",
    "            fp = len(pred_set - gt_set)\n",
    "            # False Negatives: In Ground Truth, but missed by Azure\n",
    "            fn = len(gt_set - pred_set)\n",
    "            \n",
    "            true_positives += tp\n",
    "            false_positives += fp\n",
    "            false_negatives += fn\n",
    "\n",
    "    # --- CALCULATE METRICS ---\n",
    "    # Precision: When Azure predicts PII, how often is it right?\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    \n",
    "    # Recall: Out of all actual PII, how much did Azure find?\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    \n",
    "    # F1-Score: The harmonic mean of Precision and Recall\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(\"--- EVALUATION RESULTS ---\")\n",
    "    print(f\"True Positives (Exact Matches): {true_positives}\")\n",
    "    print(f\"False Positives (Hallucinations/Over-tagging): {false_positives}\")\n",
    "    print(f\"False Negatives (Missed PII): {false_negatives}\")\n",
    "    print(\"-\" * 26)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1_score:.4f}\")\n",
    "\n",
    "evaluate_pii_dataset(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1956ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
